{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 205,
      "id": "ac2f73f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install nltk\n",
        "# !pip install matplotlib\n",
        "# !pip install tensorflow\n",
        "# !pip install pandas\n",
        "# !pip install nltk\n",
        "# !pip install matplotlib\n",
        "# !pip install scikit-learn\n",
        "# !pip install transformers\n",
        "# !pip install tf-keras\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "id": "1865518c",
      "metadata": {
        "id": "1865518c"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import seaborn as sns\n",
        "import string\n",
        "import re\n",
        "# sns.set()\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Graphics in retina format are more sharp and legible\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "id": "c5dc252a",
      "metadata": {
        "id": "c5dc252a",
        "outputId": "49dc85c3-05fc-47ec-ad09-20d4b7db41c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hyp</th>\n",
              "      <th>ref</th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>labels</th>\n",
              "      <th>label</th>\n",
              "      <th>p(Hallucination)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A sloping top .</td>\n",
              "      <td>tgt</td>\n",
              "      <td>The sides of the casket were covered with heav...</td>\n",
              "      <td>A decorative feature that sits on top of somet...</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Not Hallucination, Hallucination, Not Halluci...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To react too much .</td>\n",
              "      <td>tgt</td>\n",
              "      <td>Please try not to overreact if she drives badl...</td>\n",
              "      <td>To react too much or too intensely .</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The process of spoiling ; the state of being s...</td>\n",
              "      <td>tgt</td>\n",
              "      <td>To prevent spoilage , store in a cool , dry pl...</td>\n",
              "      <td>The process of spoiling .</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To arrange in a particular way .</td>\n",
              "      <td>tgt</td>\n",
              "      <td>The way the opposition has framed the argument...</td>\n",
              "      <td>To construct in words so as to establish a con...</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A feeling of concern ; a feeling of anxiety .</td>\n",
              "      <td>tgt</td>\n",
              "      <td>To mix with thy concernments i desist . What i...</td>\n",
              "      <td>That in which one is concerned or interested ;...</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Not Hallucination, Hallucination, Hallucinati...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 hyp  ref  \\\n",
              "0                                    A sloping top .  tgt   \n",
              "1                                To react too much .  tgt   \n",
              "2  The process of spoiling ; the state of being s...  tgt   \n",
              "3                   To arrange in a particular way .  tgt   \n",
              "4      A feeling of concern ; a feeling of anxiety .  tgt   \n",
              "\n",
              "                                                 src  \\\n",
              "0  The sides of the casket were covered with heav...   \n",
              "1  Please try not to overreact if she drives badl...   \n",
              "2  To prevent spoilage , store in a cool , dry pl...   \n",
              "3  The way the opposition has framed the argument...   \n",
              "4  To mix with thy concernments i desist . What i...   \n",
              "\n",
              "                                                 tgt  \\\n",
              "0  A decorative feature that sits on top of somet...   \n",
              "1               To react too much or too intensely .   \n",
              "2                          The process of spoiling .   \n",
              "3  To construct in words so as to establish a con...   \n",
              "4  That in which one is concerned or interested ;...   \n",
              "\n",
              "                            model task  \\\n",
              "0  ltg/flan-t5-definition-en-base   DM   \n",
              "1  ltg/flan-t5-definition-en-base   DM   \n",
              "2  ltg/flan-t5-definition-en-base   DM   \n",
              "3  ltg/flan-t5-definition-en-base   DM   \n",
              "4  ltg/flan-t5-definition-en-base   DM   \n",
              "\n",
              "                                              labels  label  p(Hallucination)  \n",
              "0  [Not Hallucination, Hallucination, Not Halluci...      1               0.6  \n",
              "1  [Not Hallucination, Not Hallucination, Not Hal...      0               0.0  \n",
              "2  [Hallucination, Not Hallucination, Hallucinati...      1               0.6  \n",
              "3  [Hallucination, Not Hallucination, Not Halluci...      1               0.6  \n",
              "4  [Not Hallucination, Hallucination, Hallucinati...      1               0.6  "
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use either top model-aware or model-agnostic\n",
        "# df = pd.read_json('../SHROOM_dev-v2_validation/val.model-agnostic.json')\n",
        "df = pd.read_json('data/val.model-aware.v2.json')\n",
        "df[\"label\"] = df[\"label\"].map({\"Hallucination\":1, \"Not Hallucination\":0})\n",
        "\n",
        "df = df.dropna(how=\"any\", axis=1)\n",
        "df.head()\n",
        "\n",
        "# also let's think about the tasks, DM, PG, MT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "id": "80dbbac9",
      "metadata": {
        "id": "80dbbac9"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stemmer    = nltk.SnowballStemmer(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65dc4634",
      "metadata": {
        "id": "65dc4634"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "id": "1ccf66a8",
      "metadata": {
        "id": "1ccf66a8"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    '''\n",
        "        Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "        and remove words containing numbers.\n",
        "    '''\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove urls\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_data(text):\n",
        "    text = clean_text(text)                                                     # Clean puntuation, urls, and so on\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)    # Remove stopwords\n",
        "#     text = ' '.join(stemmer.stem(word) for word in text.split())                # Stemm all the words in the sentence\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "id": "4125ed4d",
      "metadata": {
        "id": "4125ed4d",
        "outputId": "c4697332-cc8c-45b5-a147-8dd1f3847f50"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hyp</th>\n",
              "      <th>ref</th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "      <th>model</th>\n",
              "      <th>task</th>\n",
              "      <th>labels</th>\n",
              "      <th>label</th>\n",
              "      <th>p(Hallucination)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sloping top</td>\n",
              "      <td>tgt</td>\n",
              "      <td>sides casket covered heavy black broadcloth ve...</td>\n",
              "      <td>decorative feature sits top something</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Not Hallucination, Hallucination, Not Halluci...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>react much</td>\n",
              "      <td>tgt</td>\n",
              "      <td>please try overreact drives badly first learni...</td>\n",
              "      <td>react much intensely</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>process spoiling state spoilt</td>\n",
              "      <td>tgt</td>\n",
              "      <td>prevent spoilage store cool dry place meaning ...</td>\n",
              "      <td>process spoiling</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>arrange particular way</td>\n",
              "      <td>tgt</td>\n",
              "      <td>way opposition framed argument makes hard us w...</td>\n",
              "      <td>construct words establish context understandin...</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>feeling concern feeling anxiety</td>\n",
              "      <td>tgt</td>\n",
              "      <td>mix thy concernments desist meaning concernment</td>\n",
              "      <td>one concerned interested concern affair interest</td>\n",
              "      <td>ltg/flan-t5-definition-en-base</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Not Hallucination, Hallucination, Hallucinati...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>using gasfired device way stop people using na...</td>\n",
              "      <td>either</td>\n",
              "      <td>doonii fayyadamuun meeshaa geejibuun namootaba...</td>\n",
              "      <td>using ships transport goods far efficient way ...</td>\n",
              "      <td>facebook/nllb-200-distilled-600M</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>since montevideo located south equator summer ...</td>\n",
              "      <td>either</td>\n",
              "      <td>وبما أن مونتيفيديو موجودة في جنوب خط الاستواء،...</td>\n",
              "      <td>since montevideo south equator summer winter n...</td>\n",
              "      <td>facebook/nllb-200-distilled-600M</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>also supporter singapores deputy prime ministe...</td>\n",
              "      <td>either</td>\n",
              "      <td>ginabiabi hiya han deputy prime minister han s...</td>\n",
              "      <td>greeted singapores deputy prime minister wong ...</td>\n",
              "      <td>facebook/nllb-200-distilled-600M</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Hallucination, Hallucination, Not Hallucinati...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>concept worm parasitic organisms trained behav...</td>\n",
              "      <td>either</td>\n",
              "      <td>འབུ་ཞེས་པའི་ཐ་སྙད་དེ་ཉིད་འབུ་སྲིན་དཔྱད་རིག་པ་བ...</td>\n",
              "      <td>term bug used entomologists formal sense group...</td>\n",
              "      <td>facebook/nllb-200-distilled-600M</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>exception fact us government able negotiate co...</td>\n",
              "      <td>either</td>\n",
              "      <td>ihandjika iyakwece hali kulihana iya kutunguis...</td>\n",
              "      <td>liberal criticism reconstruction effort focuse...</td>\n",
              "      <td>facebook/nllb-200-distilled-600M</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Not Hallucination, Not Hallucination, Halluci...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>501 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   hyp     ref  \\\n",
              "0                                          sloping top     tgt   \n",
              "1                                           react much     tgt   \n",
              "2                        process spoiling state spoilt     tgt   \n",
              "3                               arrange particular way     tgt   \n",
              "4                      feeling concern feeling anxiety     tgt   \n",
              "..                                                 ...     ...   \n",
              "496  using gasfired device way stop people using na...  either   \n",
              "497  since montevideo located south equator summer ...  either   \n",
              "498  also supporter singapores deputy prime ministe...  either   \n",
              "499  concept worm parasitic organisms trained behav...  either   \n",
              "500  exception fact us government able negotiate co...  either   \n",
              "\n",
              "                                                   src  \\\n",
              "0    sides casket covered heavy black broadcloth ve...   \n",
              "1    please try overreact drives badly first learni...   \n",
              "2    prevent spoilage store cool dry place meaning ...   \n",
              "3    way opposition framed argument makes hard us w...   \n",
              "4      mix thy concernments desist meaning concernment   \n",
              "..                                                 ...   \n",
              "496  doonii fayyadamuun meeshaa geejibuun namootaba...   \n",
              "497  وبما أن مونتيفيديو موجودة في جنوب خط الاستواء،...   \n",
              "498  ginabiabi hiya han deputy prime minister han s...   \n",
              "499  འབུ་ཞེས་པའི་ཐ་སྙད་དེ་ཉིད་འབུ་སྲིན་དཔྱད་རིག་པ་བ...   \n",
              "500  ihandjika iyakwece hali kulihana iya kutunguis...   \n",
              "\n",
              "                                                   tgt  \\\n",
              "0                decorative feature sits top something   \n",
              "1                                 react much intensely   \n",
              "2                                     process spoiling   \n",
              "3    construct words establish context understandin...   \n",
              "4     one concerned interested concern affair interest   \n",
              "..                                                 ...   \n",
              "496  using ships transport goods far efficient way ...   \n",
              "497  since montevideo south equator summer winter n...   \n",
              "498  greeted singapores deputy prime minister wong ...   \n",
              "499  term bug used entomologists formal sense group...   \n",
              "500  liberal criticism reconstruction effort focuse...   \n",
              "\n",
              "                                model task  \\\n",
              "0      ltg/flan-t5-definition-en-base   DM   \n",
              "1      ltg/flan-t5-definition-en-base   DM   \n",
              "2      ltg/flan-t5-definition-en-base   DM   \n",
              "3      ltg/flan-t5-definition-en-base   DM   \n",
              "4      ltg/flan-t5-definition-en-base   DM   \n",
              "..                                ...  ...   \n",
              "496  facebook/nllb-200-distilled-600M   MT   \n",
              "497  facebook/nllb-200-distilled-600M   MT   \n",
              "498  facebook/nllb-200-distilled-600M   MT   \n",
              "499  facebook/nllb-200-distilled-600M   MT   \n",
              "500  facebook/nllb-200-distilled-600M   MT   \n",
              "\n",
              "                                                labels  label  \\\n",
              "0    [Not Hallucination, Hallucination, Not Halluci...      1   \n",
              "1    [Not Hallucination, Not Hallucination, Not Hal...      0   \n",
              "2    [Hallucination, Not Hallucination, Hallucinati...      1   \n",
              "3    [Hallucination, Not Hallucination, Not Halluci...      1   \n",
              "4    [Not Hallucination, Hallucination, Hallucinati...      1   \n",
              "..                                                 ...    ...   \n",
              "496  [Hallucination, Hallucination, Hallucination, ...      1   \n",
              "497  [Not Hallucination, Not Hallucination, Not Hal...      0   \n",
              "498  [Hallucination, Hallucination, Not Hallucinati...      1   \n",
              "499  [Hallucination, Hallucination, Hallucination, ...      1   \n",
              "500  [Not Hallucination, Not Hallucination, Halluci...      0   \n",
              "\n",
              "     p(Hallucination)  \n",
              "0                 0.6  \n",
              "1                 0.0  \n",
              "2                 0.6  \n",
              "3                 0.6  \n",
              "4                 0.6  \n",
              "..                ...  \n",
              "496               1.0  \n",
              "497               0.0  \n",
              "498               0.8  \n",
              "499               1.0  \n",
              "500               0.4  \n",
              "\n",
              "[501 rows x 9 columns]"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns = ['hyp','src','tgt'] # exclude task\n",
        "for x in columns:\n",
        "    df[x] = df[x].apply(preprocess_data)\n",
        "\n",
        "# X = np.reshape(X,(499))\n",
        "# X.shape, y.shape\n",
        "# X = df.drop(['label','labels', 'model', 'p(Hallucination)','task','ref'], axis=1)\n",
        "# y = df['label']\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "id": "b76393a4",
      "metadata": {
        "id": "b76393a4"
      },
      "outputs": [],
      "source": [
        "# extract preprocessed data as CSV file,\n",
        "# also i extract them based on tasks, so that they can be fed separately\n",
        "df = df.drop(['labels'], axis=1)\n",
        "dm_df = df[df['task'] == 'DM']\n",
        "mt_df = df[df['task'] == 'MT']\n",
        "pg_df = df[df['task'] == 'PG']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "id": "f543eb1e",
      "metadata": {
        "id": "f543eb1e",
        "outputId": "6433ff4b-5c0f-493a-f208-266b5d3469ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(188, 188, 125)"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dm_df),len(mt_df), len(pg_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "id": "7dedccc3",
      "metadata": {
        "id": "7dedccc3",
        "outputId": "40b4458c-2d53-44fa-aead-09287d131950"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "hyp                 0\n",
              "ref                 0\n",
              "src                 0\n",
              "tgt                 0\n",
              "model               0\n",
              "task                0\n",
              "label               0\n",
              "p(Hallucination)    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "number_of_na = pg_df.isna().sum()\n",
        "number_of_na"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "id": "2d656088",
      "metadata": {
        "id": "2d656088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/thesis_data_before\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "# file_path = '/Users/byun/Desktop/School/semeval/eda_nlp/thesis_data_before/'\n",
        "file_path = r\"C:\\Users\\marko\\OneDrive\\바탕 화면\\semeval\\Task 6 - windows\\eda_nlp-20240601T173748Z-001\\thesis_data_before\"\n",
        "file_path_uni = pathlib.Path(file_path).as_posix()\n",
        "print(file_path_uni)\n",
        "# Save the DataFrame as a CSV file at the specified location\n",
        "dm_df.to_csv(file_path_uni + 'dm_df.csv', index=False)\n",
        "mt_df.to_csv(file_path_uni + 'mt_df.csv', index=False)\n",
        "pg_df.to_csv(file_path_uni + 'pg_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "id": "b521f9dc",
      "metadata": {
        "id": "b521f9dc"
      },
      "outputs": [],
      "source": [
        "# C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/thesis_data_after\n",
        "# task PG, num_aug 16\n",
        "pg_rd_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/pg_df_rd.csv'\n",
        "pg_ri_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/pg_df_ri.csv'\n",
        "pg_rs_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rs/pg_df_rs.csv'\n",
        "pg_sr_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/sr/pg_df_sr.csv'\n",
        "\n",
        "pg_rd = pd.read_csv(pg_rd_path)\n",
        "pg_ri = pd.read_csv(pg_ri_path)\n",
        "pg_rs = pd.read_csv(pg_rs_path)\n",
        "pg_sr = pd.read_csv(pg_sr_path)\n",
        "\n",
        "# num_aug 160\n",
        "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/pg_df_rd.csv'\n",
        "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/pg_df_ri.csv'\n",
        "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rs/pg_df_rs.csv'\n",
        "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/sr/pg_df_sr.csv'\n",
        "\n",
        "pg_rd_160 = pd.read_csv(path1)\n",
        "pg_ri_160 = pd.read_csv(path2)\n",
        "pg_rs_160 = pd.read_csv(path3)\n",
        "pg_sr_160 = pd.read_csv(path4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "id": "8033caa1",
      "metadata": {
        "id": "8033caa1"
      },
      "outputs": [],
      "source": [
        "# task DM 16\n",
        "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/dm_df_rd.csv'\n",
        "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/dm_df_ri.csv'\n",
        "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rs/dm_df_rs.csv'\n",
        "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/sr/dm_df_sr.csv'\n",
        "\n",
        "dm_rd = pd.read_csv(path1)\n",
        "dm_ri = pd.read_csv(path2)\n",
        "dm_rs = pd.read_csv(path3)\n",
        "dm_sr = pd.read_csv(path4)\n",
        "\n",
        "# 160\n",
        "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/rd/dm_df_rd.csv'\n",
        "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/ri/dm_df_ri.csv'\n",
        "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/rs/dm_df_rs.csv'\n",
        "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/sr/dm_df_sr.csv'\n",
        "\n",
        "dm_rd_160 = pd.read_csv(path1)\n",
        "dm_ri_160 = pd.read_csv(path2)\n",
        "dm_rs_160 = pd.read_csv(path3)\n",
        "dm_sr_160 = pd.read_csv(path4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "id": "9eea0f24",
      "metadata": {
        "id": "9eea0f24"
      },
      "outputs": [],
      "source": [
        "# task MT 16\n",
        "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/mt_df_rd.csv'\n",
        "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/mt_df_ri.csv'\n",
        "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rs/mt_df_rs.csv'\n",
        "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/sr/mt_df_sr.csv'\n",
        "\n",
        "mt_rd = pd.read_csv(path1)\n",
        "mt_ri = pd.read_csv(path2)\n",
        "mt_rs = pd.read_csv(path3)\n",
        "mt_sr = pd.read_csv(path4)\n",
        "\n",
        "# 160\n",
        "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/rd/mt_df_rd.csv'\n",
        "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/ri/mt_df_ri.csv'\n",
        "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/rs/mt_df_rs.csv'\n",
        "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/sr/mt_df_sr.csv'\n",
        "\n",
        "mt_rd_160 = pd.read_csv(path1)\n",
        "mt_ri_160 = pd.read_csv(path2)\n",
        "mt_rs_160 = pd.read_csv(path3)\n",
        "mt_sr_160 = pd.read_csv(path4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "id": "24240c67",
      "metadata": {
        "id": "24240c67"
      },
      "outputs": [],
      "source": [
        "#\n",
        "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/mt_df_rd.csv'\n",
        "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/mt_df_ri.csv'\n",
        "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rs/mt_df_rs.csv'\n",
        "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/sr/mt_df_sr.csv'\n",
        "\n",
        "mt_rd = pd.read_csv(path1)\n",
        "mt_ri = pd.read_csv(path2)\n",
        "mt_rs = pd.read_csv(path3)\n",
        "mt_sr = pd.read_csv(path4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "id": "76d0a9d4",
      "metadata": {
        "id": "76d0a9d4",
        "outputId": "83d49d31-7a74-4252-9062-1dcf715159de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hyp</th>\n",
              "      <th>ref</th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "      <th>model</th>\n",
              "      <th>label</th>\n",
              "      <th>p(Hallucination)</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>john john one</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>john ann like</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>john john one</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>john ann like</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>john john one</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>john ann like</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>john one</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>john ann</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>john john one</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>john ann like</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7849</th>\n",
              "      <td>dont money buy dictionary</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>money buy dictionary</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7850</th>\n",
              "      <td>dont money buy dictionary</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>buy dictionary</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7851</th>\n",
              "      <td>dont money buy dictionary</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>money buy dictionary</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7852</th>\n",
              "      <td>dont money buy dictionary</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>money buy dictionary</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7853</th>\n",
              "      <td>dont money buy dictionary</td>\n",
              "      <td>either</td>\n",
              "      <td></td>\n",
              "      <td>money buy dictionary</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7854 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            hyp     ref src                   tgt model  \\\n",
              "0                 john john one  either             john ann like         \n",
              "1                 john john one  either             john ann like         \n",
              "2                 john john one  either             john ann like         \n",
              "3                      john one  either                  john ann         \n",
              "4                 john john one  either             john ann like         \n",
              "...                         ...     ...  ..                   ...   ...   \n",
              "7849  dont money buy dictionary  either      money buy dictionary         \n",
              "7850  dont money buy dictionary  either            buy dictionary         \n",
              "7851  dont money buy dictionary  either      money buy dictionary         \n",
              "7852  dont money buy dictionary  either      money buy dictionary         \n",
              "7853  dont money buy dictionary  either      money buy dictionary         \n",
              "\n",
              "      label  p(Hallucination) Unnamed: 7  \n",
              "0         1               1.0             \n",
              "1         1               1.0             \n",
              "2         1               1.0             \n",
              "3         1               1.0             \n",
              "4         1               1.0             \n",
              "...     ...               ...        ...  \n",
              "7849      0               0.0             \n",
              "7850      0               0.0             \n",
              "7851      0               0.0             \n",
              "7852      0               0.0             \n",
              "7853      0               0.0             \n",
              "\n",
              "[7854 rows x 8 columns]"
            ]
          },
          "execution_count": 219,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pg_rd = pg_rd.dropna(how=\"any\", axis=1)\n",
        "pg_rd = pg_rd.fillna('')\n",
        "pg_ri = pg_ri.fillna('')\n",
        "pg_rs = pg_rs.fillna('')\n",
        "pg_sr = pg_sr.fillna('')\n",
        "\n",
        "dm_rd = dm_rd.fillna('')\n",
        "dm_ri = dm_ri.fillna('')\n",
        "dm_rs = dm_rs.fillna('')\n",
        "dm_sr = dm_sr.fillna('')\n",
        "\n",
        "mt_rd = mt_rd.fillna('')\n",
        "mt_ri = mt_ri.fillna('')\n",
        "mt_rs = mt_rs.fillna('')\n",
        "mt_sr = mt_sr.fillna('')\n",
        "\n",
        "pg_rd_160 = pg_rd_160.fillna('')\n",
        "pg_ri_160 = pg_ri_160.fillna('')\n",
        "pg_rs_160 = pg_rs_160.fillna('')\n",
        "pg_sr_160 = pg_sr_160.fillna('')\n",
        "\n",
        "dm_rd_160 = dm_rd_160.fillna('')\n",
        "dm_ri_160 = dm_ri_160.fillna('')\n",
        "dm_rs_160 = dm_rs_160.fillna('')\n",
        "dm_sr_160 = dm_sr_160.fillna('')\n",
        "\n",
        "mt_rd_160 = mt_rd_160.fillna('')\n",
        "mt_ri_160 = mt_ri_160.fillna('')\n",
        "mt_rs_160 = mt_rs_160.fillna('')\n",
        "mt_sr_160 = mt_sr_160.fillna('')\n",
        "# drop na just deleted the model column i think\n",
        "mt_rd_160"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9dc490",
      "metadata": {
        "id": "8c9dc490"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "id": "89942019",
      "metadata": {
        "id": "89942019"
      },
      "outputs": [],
      "source": [
        "# mt_rd_160.set_format('tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "id": "3aa8a4ce",
      "metadata": {
        "id": "3aa8a4ce"
      },
      "outputs": [],
      "source": [
        "# original dataset before data aug\n",
        "# X, y = pg_df['hyp'], pg_df['label']\n",
        "# X, y = dm_df['hyp'], dm_df['label']\n",
        "# X, y = mt_df['hyp'], mt_df['label']\n",
        "\n",
        "# task PG\n",
        "# X, y = pg_rd['hyp'] , pg_rd['label']\n",
        "# X, y = pg_ri['hyp'] , pg_ri['label']\n",
        "# X, y = pg_rs['hyp'] , pg_rs['label']\n",
        "X, y = pg_sr['hyp'] , pg_sr['label']\n",
        "# task DM\n",
        "# X, y = dm_rd['hyp'] , dm_rd['label']\n",
        "# X, y = dm_ri['hyp'] , dm_ri['label']\n",
        "# X, y = dm_rs['hyp'] , dm_rs['label']\n",
        "# X, y = dm_sr['hyp'] , dm_sr['label']\n",
        "# task MT\n",
        "# X, y = mt_rd['hyp'] , mt_rd['label']\n",
        "# X, y = mt_ri['hyp'] , mt_ri['label']\n",
        "# X, y = mt_rs['hyp'] , mt_rs['label']\n",
        "# X, y = mt_sr['hyp'] , mt_sr['label']\n",
        "\n",
        "# X, y = df['hyp'], df['label']\n",
        "# one way of getting label where task is DM, df.loc[df['task'] == 'DM', 'label']\n",
        "# X, y = df[df['task'] == 'PG']['hyp'], df[df['task'] == 'PG']['label']\n",
        "\n",
        "# task PG\n",
        "# X, y = pg_rd_160['hyp'] , pg_rd_160['label']\n",
        "# X, y = pg_ri_160['hyp'] , pg_ri_160['label']\n",
        "# X, y = pg_rs_160['hyp'] , pg_rs_160['label']\n",
        "# X, y = pg_sr_160['hyp'] , pg_sr_160['label']\n",
        "# task DM\n",
        "# X, y = dm_rd_160['hyp'] , dm_rd_160['label']\n",
        "# X, y = dm_ri_160['hyp'] , dm_ri_160['label']\n",
        "# X, y = dm_rs_160['hyp'] , dm_rs_160['label']\n",
        "# X, y = dm_sr_160['hyp'] , dm_sr_160['label']\n",
        "# task MT\n",
        "# X, y = mt_rd_160['hyp'] , mt_rd_160['label']\n",
        "# X, y = mt_ri_160['hyp'] , mt_ri_160['label']\n",
        "# X, y = mt_rs_160['hyp'] , mt_rs_160['label']\n",
        "# X, y = mt_sr_160['hyp'] , mt_sr_160['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "id": "fa5e2fe1",
      "metadata": {
        "id": "fa5e2fe1",
        "outputId": "77ee464f-18ec-496c-e1a3-638ff5e05d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution:\n",
            " label\n",
            "0    480\n",
            "1    270\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Class distribution:\\n\", y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "id": "8b538fc7",
      "metadata": {
        "id": "8b538fc7"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "\n",
        "y = np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "526216fc",
      "metadata": {
        "id": "526216fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "id": "88cebbb3",
      "metadata": {
        "id": "88cebbb3"
      },
      "outputs": [],
      "source": [
        "for i in range(len(X)):\n",
        "    X[i] = str(X[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "id": "3eaf8598",
      "metadata": {
        "id": "3eaf8598",
        "outputId": "420602d0-fe95-49ea-a880-cdd03fbfc2c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(600, 600, 150, 150)"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# split into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,  random_state=42)\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "id": "f1a60ffb",
      "metadata": {
        "id": "f1a60ffb",
        "outputId": "f7c77011-b10c-4aab-b256-b95dabd10e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of na: hyp                 0\n",
            "ref                 0\n",
            "src                 0\n",
            "tgt                 0\n",
            "model               0\n",
            "task                0\n",
            "label               0\n",
            "p(Hallucination)    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# count number of none 0 or 1s\n",
        "number_of_na = df.isna().sum()\n",
        "print(\"Number of na:\", number_of_na)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "id": "3f7932d7",
      "metadata": {
        "id": "3f7932d7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "id": "6dad4792",
      "metadata": {
        "id": "6dad4792"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf = TfidfTransformer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "id": "e8f529cd",
      "metadata": {
        "id": "e8f529cd",
        "outputId": "ca666780-0621-4a94-f6de-b3a64cd326e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-5 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-5 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-5 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-5 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-5 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-5 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-5 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 229,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_cv, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "id": "e571d435",
      "metadata": {
        "id": "e571d435"
      },
      "outputs": [],
      "source": [
        "# predict classes\n",
        "y_pred = nb.predict(X_test_cv)\n",
        "y_pred_proba = nb.predict_proba(X_test_cv)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "id": "bd5bfcd2",
      "metadata": {
        "id": "bd5bfcd2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "id": "582deaed",
      "metadata": {
        "id": "582deaed",
        "outputId": "4b89011c-8950-460f-cc3a-f932b9c26886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision is  -> 0.98\n",
            "recall is -> 0.99\n",
            "f1_score is -> 0.99\n"
          ]
        }
      ],
      "source": [
        "p, r, f, _ = precision_recall_fscore_support(y_test, y_pred,\n",
        "                                                 average='macro')\n",
        "print(f'precision is  -> {round(p,2)}')\n",
        "print(f'recall is -> {round(r,2)}')\n",
        "print(f'f1_score is -> {round(f,2)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "id": "4cc9fc3e",
      "metadata": {
        "id": "4cc9fc3e",
        "outputId": "21614f31-ceef-4708-f1f6-ed20bb56abed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is -> 0.99\n"
          ]
        }
      ],
      "source": [
        "# calculate the accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy is -> {round(acc,2)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "id": "a317bd7b",
      "metadata": {
        "id": "a317bd7b",
        "outputId": "46867600-f312-4209-a100-4bcbd526edb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The confusion_matrix is: \n",
            " [[88  2]\n",
            " [ 0 60]]\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('The confusion_matrix is: \\n', cm);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "id": "06bee6c0",
      "metadata": {
        "id": "06bee6c0"
      },
      "outputs": [],
      "source": [
        "# no import mlxtend? but does not matter too much so skip\n",
        "# from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "# fig, ax = plot_confusion_matrix(conf_mat= cm, colorbar=True)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "id": "affed018",
      "metadata": {
        "id": "affed018",
        "outputId": "f2dc246e-7978-4497-8ddb-3c86b68fcfdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The roc_auc Score is -> 0.99\n"
          ]
        }
      ],
      "source": [
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f'The roc_auc Score is -> {round(roc_auc,2)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "id": "95d3d5c8",
      "metadata": {
        "id": "95d3d5c8",
        "outputId": "1d36b3a7-c015-475b-d084-ec1c9871f44d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-6 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-6 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-6 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-6 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-6 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-6 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-6 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-6 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;bow&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;model&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;bow&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;model&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfTransformer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('bow', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('model', MultinomialNB())])"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([('bow', CountVectorizer()),\n",
        "                 ('tfidf', TfidfTransformer()),\n",
        "                 ('model', MultinomialNB())])\n",
        "\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "id": "123e3e89",
      "metadata": {
        "id": "123e3e89"
      },
      "outputs": [],
      "source": [
        "y_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "id": "19d5fbed",
      "metadata": {
        "id": "19d5fbed",
        "outputId": "7171161e-e580-4ac9-fabf-a6b752252e46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "id": "6c066c6d",
      "metadata": {
        "id": "6c066c6d",
        "outputId": "ae99a332-4242-44e8-a6f8-7da6a3a25e89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[85,  5],\n",
              "       [ 5, 55]], dtype=int64)"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "id": "8326f8a1",
      "metadata": {
        "id": "8326f8a1",
        "outputId": "44844017-aaa5-4ff6-c1c2-30e6a15e613b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "      <th>hyp</th>\n",
              "      <th>task</th>\n",
              "      <th>labels</th>\n",
              "      <th>label</th>\n",
              "      <th>p(Hallucination)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ты удивишься если я скажу что на самом деле ме...</td>\n",
              "      <td>would surprised told name isnt actually tom</td>\n",
              "      <td>youre gonna surprised say real name isnt tom</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>еды будет полно</td>\n",
              "      <td>plenty food</td>\n",
              "      <td>food full</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>думаете том будет меня ждать</td>\n",
              "      <td>think tom wait</td>\n",
              "      <td>think toms gonna wait</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>два брата довольно разные</td>\n",
              "      <td>two brothers pretty different</td>\n",
              "      <td>theres lot friends</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>infradiaphragmatic intra suprasellar craniopha...</td>\n",
              "      <td>medicine diaphragm</td>\n",
              "      <td>anatomy relating diaphragm</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>2992</td>\n",
              "      <td>я никогда не говорил мэри что чувствую</td>\n",
              "      <td>never told mary felt</td>\n",
              "      <td>ive never told mary feel</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>2993</td>\n",
              "      <td>beat rat tailed kyoodle runs steers eric laid ...</td>\n",
              "      <td>mutt dog mixed breed little value noisy dog</td>\n",
              "      <td>slang mustang</td>\n",
              "      <td>DM</td>\n",
              "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>2994</td>\n",
              "      <td>ты знаешь почему они прекратили говорить</td>\n",
              "      <td>know stopped talking</td>\n",
              "      <td>know stopped talking</td>\n",
              "      <td>MT</td>\n",
              "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>2996</td>\n",
              "      <td>anyone back</td>\n",
              "      <td>anyone confirm</td>\n",
              "      <td>anyone corroborate</td>\n",
              "      <td>PG</td>\n",
              "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>2999</td>\n",
              "      <td>oh michael youre scaring</td>\n",
              "      <td>frighten</td>\n",
              "      <td>oh michael scare</td>\n",
              "      <td>PG</td>\n",
              "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                                src  \\\n",
              "0        1  ты удивишься если я скажу что на самом деле ме...   \n",
              "1        2                                    еды будет полно   \n",
              "2        3                       думаете том будет меня ждать   \n",
              "3        6                          два брата довольно разные   \n",
              "4        7  infradiaphragmatic intra suprasellar craniopha...   \n",
              "...    ...                                                ...   \n",
              "1495  2992             я никогда не говорил мэри что чувствую   \n",
              "1496  2993  beat rat tailed kyoodle runs steers eric laid ...   \n",
              "1497  2994           ты знаешь почему они прекратили говорить   \n",
              "1498  2996                                        anyone back   \n",
              "1499  2999                           oh michael youre scaring   \n",
              "\n",
              "                                              tgt  \\\n",
              "0     would surprised told name isnt actually tom   \n",
              "1                                     plenty food   \n",
              "2                                  think tom wait   \n",
              "3                   two brothers pretty different   \n",
              "4                              medicine diaphragm   \n",
              "...                                           ...   \n",
              "1495                         never told mary felt   \n",
              "1496  mutt dog mixed breed little value noisy dog   \n",
              "1497                         know stopped talking   \n",
              "1498                               anyone confirm   \n",
              "1499                                     frighten   \n",
              "\n",
              "                                               hyp task  \\\n",
              "0     youre gonna surprised say real name isnt tom   MT   \n",
              "1                                        food full   MT   \n",
              "2                            think toms gonna wait   MT   \n",
              "3                               theres lot friends   MT   \n",
              "4                       anatomy relating diaphragm   DM   \n",
              "...                                            ...  ...   \n",
              "1495                      ive never told mary feel   MT   \n",
              "1496                                 slang mustang   DM   \n",
              "1497                          know stopped talking   MT   \n",
              "1498                            anyone corroborate   PG   \n",
              "1499                              oh michael scare   PG   \n",
              "\n",
              "                                                 labels  label  \\\n",
              "0     [Not Hallucination, Not Hallucination, Not Hal...      0   \n",
              "1     [Hallucination, Not Hallucination, Hallucinati...      1   \n",
              "2     [Not Hallucination, Not Hallucination, Not Hal...      0   \n",
              "3     [Hallucination, Hallucination, Hallucination, ...      1   \n",
              "4     [Hallucination, Hallucination, Hallucination, ...      1   \n",
              "...                                                 ...    ...   \n",
              "1495  [Hallucination, Not Hallucination, Not Halluci...      0   \n",
              "1496  [Hallucination, Hallucination, Hallucination, ...      1   \n",
              "1497  [Hallucination, Not Hallucination, Not Halluci...      0   \n",
              "1498  [Not Hallucination, Not Hallucination, Not Hal...      0   \n",
              "1499  [Not Hallucination, Not Hallucination, Not Hal...      0   \n",
              "\n",
              "      p(Hallucination)  \n",
              "0                  0.0  \n",
              "1                  0.8  \n",
              "2                  0.2  \n",
              "3                  1.0  \n",
              "4                  0.8  \n",
              "...                ...  \n",
              "1495               0.4  \n",
              "1496               1.0  \n",
              "1497               0.4  \n",
              "1498               0.0  \n",
              "1499               0.0  \n",
              "\n",
              "[1500 rows x 8 columns]"
            ]
          },
          "execution_count": 241,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# paths to final test data\n",
        "final_ag_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/final_test_data/test.model-agnostic.json'\n",
        "final_aw_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/final_test_data/test.model-agnostic.json'\n",
        "\n",
        "final_ag_df = pd.read_json(final_ag_path)\n",
        "final_aw_df = pd.read_json(final_aw_path)\n",
        "final_ag_df[\"label\"] = final_ag_df[\"label\"].map({\"Hallucination\":1, \"Not Hallucination\":0})\n",
        "final_aw_df[\"label\"] = final_aw_df[\"label\"].map({\"Hallucination\":1, \"Not Hallucination\":0})\n",
        "# perform preprocessing on final_df AND split it based on tasks!\n",
        "columns = ['hyp','src','tgt'] # exclude task\n",
        "for x in columns:\n",
        "    final_ag_df[x] = final_ag_df[x].apply(preprocess_data)\n",
        "for x in columns:\n",
        "    final_aw_df[x] = final_aw_df[x].apply(preprocess_data)\n",
        "final_ag_pg = final_ag_df[final_ag_df['task'] == 'PG']\n",
        "final_ag_dm = final_ag_df[final_ag_df['task'] == 'DM']\n",
        "final_ag_mt = final_ag_df[final_ag_df['task'] == 'MT']\n",
        "\n",
        "final_aw_pg = final_aw_df[final_aw_df['task'] == 'PG']\n",
        "final_aw_dm = final_aw_df[final_aw_df['task'] == 'DM']\n",
        "final_aw_mt = final_aw_df[final_aw_df['task'] == 'MT']\n",
        "\n",
        "final_ag_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "id": "87048aed",
      "metadata": {
        "id": "87048aed"
      },
      "outputs": [],
      "source": [
        "# import xgboost as xgb\n",
        "\n",
        "# xgb_pipe = Pipeline([\n",
        "#                 ('bow', CountVectorizer()),\n",
        "#                 ('tfidf', TfidfTransformer()),\n",
        "#                 ('model', xgb.XGBClassifier(\n",
        "#                     learning_rate=0.1,\n",
        "#                     max_depth=7,\n",
        "#                     n_estimators=80,\n",
        "#                     use_label_encoder=False,\n",
        "#                     eval_metric='auc'))\n",
        "#                 ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "id": "a6fd184c",
      "metadata": {
        "id": "a6fd184c",
        "outputId": "94d6d507-620f-49aa-c507-c396f9d34dfd"
      },
      "outputs": [],
      "source": [
        "# # Fit the pipeline with the data\n",
        "# xgb_pipe.fit(X_train, y_train)\n",
        "\n",
        "# y_pred = xgb_pipe.predict(X_test)\n",
        "# # y_pred_train = pipe.predict(X_train)\n",
        "\n",
        "# # print('Train: {}'.format(accuracy_score(y_train, y_pred_train)))\n",
        "# print(f'Accuracy Score For Test Data: -> {round(accuracy_score(y_test, y_pred),2)}')\n",
        "# print(f'Confusion Matrix Score For Test Data:\\n {confusion_matrix(y_test, y_pred)}')\n",
        "# # calculate the accuracy\n",
        "# acc = accuracy_score(y_test, y_pred)\n",
        "# print(f'xgboost Accuracy is -> {round(acc,2)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6234481b",
      "metadata": {
        "id": "6234481b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74fa4a12",
      "metadata": {
        "id": "74fa4a12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "id": "cc9b9eaf",
      "metadata": {
        "id": "cc9b9eaf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "id": "57f78f39",
      "metadata": {
        "id": "57f78f39",
        "outputId": "46a22043-ce14-49e0-f049-0985afb555c3"
      },
      "outputs": [],
      "source": [
        "# # Perform cross-validation\n",
        "# cv_scores = cross_val_score(xgb_pipe, X, y, cv=10)  # 5-fold cross-validation\n",
        "\n",
        "# # Print the cross-validation scores\n",
        "# print(\"Cross-validation scores:\", cv_scores)\n",
        "# print(\"Mean CV score:\", cv_scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "id": "023d1e55",
      "metadata": {
        "id": "023d1e55",
        "outputId": "626bb6c9-a1bd-4522-dea5-5f9a4f4cbe03"
      },
      "outputs": [],
      "source": [
        "# final two datasets\n",
        "ag_X, ag_y = final_ag_pg['hyp'], final_ag_pg['label']\n",
        "# ag_X, ag_y = final_ag_dm['hyp'], final_ag_dm['label']\n",
        "# ag_X, ag_y = final_ag_mt['hyp'], final_ag_mt['label']\n",
        "\n",
        "# ag_X, ag_y = final_aw_pg['hyp'], final_aw_pg['label']\n",
        "# ag_X, ag_y = final_aw_dm['hyp'], final_aw_dm['label']\n",
        "# ag_X, ag_y = final_aw_mt['hyp'], final_aw_mt['label']\n",
        "\n",
        "# ag_X = count_vect.transform(ag_X)\n",
        "# ag_X = tfidf_transformer.transform(ag_X)\n",
        "\n",
        "# final_y = xgb_pipe.predict(ag_X)\n",
        "# final_accuracy_tt = accuracy_score(ag_y, final_y)\n",
        "# print(f'test/train split xgboost Accuracy is -> {round(acc,2)}')\n",
        "# print(\"XGB train/test split prediction with final TEST dataset:\", final_accuracy_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "id": "d7739461",
      "metadata": {
        "id": "d7739461",
        "outputId": "017ae5e2-c0c9-45ac-b519-de207c04a880"
      },
      "outputs": [],
      "source": [
        "# # implement cross validation manually to see if it leads to better accuracy for XGB\n",
        "# import numpy as np\n",
        "# import xgboost as xgb\n",
        "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Example data (X should be your feature matrix and y your labels)\n",
        "# # X, y = ...\n",
        "\n",
        "# # Number of folds\n",
        "# n_folds = 5\n",
        "\n",
        "# # Shuffle and split the data into 5 folds\n",
        "# indices = np.arange(X.shape[0])\n",
        "# np.random.shuffle(indices)\n",
        "# folds = np.array_split(indices, n_folds)\n",
        "\n",
        "# # Store the accuracy scores for each fold\n",
        "# accuracy_scores = []\n",
        "# ag_accuracy_scores = []\n",
        "# aw_accuracy_scores = []\n",
        "\n",
        "# # Define the model configuration\n",
        "# model_config = {\n",
        "#     'learning_rate': 0.1,\n",
        "#     'max_depth': 7,\n",
        "#     'n_estimators': 80,\n",
        "#     'use_label_encoder': False,\n",
        "#     'eval_metric': 'auc'\n",
        "# }\n",
        "# # model = xgb.XGBClassifier(**model_config)\n",
        "\n",
        "# for i in range(n_folds):\n",
        "#     # Prepare the training and validation sets\n",
        "#     val_indices = folds[i]\n",
        "#     train_indices = np.hstack([folds[j] for j in range(n_folds) if j != i])\n",
        "\n",
        "#     X_train, X_val = X[train_indices], X[val_indices]\n",
        "#     y_train, y_val = y[train_indices], y[val_indices]\n",
        "\n",
        "#     # Create the pipeline components\n",
        "#     count_vect = CountVectorizer()\n",
        "#     tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "#     # Fit and transform the training data\n",
        "#     X_train_counts = count_vect.fit_transform(X_train)\n",
        "#     X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "#     # Fit and transform the validation data\n",
        "#     X_val_counts = count_vect.transform(X_val)\n",
        "#     X_val_tfidf = tfidf_transformer.transform(X_val_counts)\n",
        "\n",
        "#     # Train the model\n",
        "#     model = xgb.XGBClassifier(**model_config)\n",
        "#     model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "#     # Predict on the validation set\n",
        "#     y_pred = model.predict(X_val_tfidf)\n",
        "\n",
        "#     # predict using actual final data from semeval (5/17)\n",
        "# #     ag_X_ag, ag_y_ag = final_ag_df['hyp'], final_ag_df['label']\n",
        "# #     ag_X_aw, ag_y_aw = final_aw_df['hyp'], final_aw_df['label']\n",
        "#     # Calculate accuracy\n",
        "#     accuracy = accuracy_score(y_val, y_pred)\n",
        "#     accuracy_scores.append(accuracy)\n",
        "\n",
        "# #     ag_accuracy = accuracy_score()\n",
        "# #     ag_accuracy_scores.append(ag_accuracy)\n",
        "# #     aw_accuracy_scores.append(aw_accuracy)\n",
        "\n",
        "# # Calculate the mean accuracy\n",
        "# mean_accuracy = np.mean(accuracy_scores)\n",
        "\n",
        "# print(\"XGB Cross-validation accuracy scores:\", accuracy_scores)\n",
        "# print(\"XGB Mean cross-validation accuracy:\", mean_accuracy)\n",
        "\n",
        "# # final two datasets\n",
        "\n",
        "# ag_X = count_vect.transform(ag_X)\n",
        "# ag_X = tfidf_transformer.transform(ag_X)\n",
        "# final_y = model.predict(ag_X)\n",
        "# final_accuracy = accuracy_score(ag_y, final_y)\n",
        "# print(\"XGB final prediction with final TEST dataset:\", final_accuracy)\n",
        "\n",
        "# # train/test split\n",
        "# print(f'test/train split xgboost Accuracy is -> {round(acc,2)}')\n",
        "# print(\"XGB train/test split prediction with final TEST dataset:\", final_accuracy_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "30778a48",
      "metadata": {
        "id": "30778a48",
        "outputId": "301e0fa4-afb7-4c28-a681-eb8383703525"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import TFBertForSequenceClassification, BertTokenizer, AutoTokenizer, TFAutoModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "checkpoint = 'bert-base-uncased'\n",
        "# checkpoint = 'bert-large-uncased'\n",
        "# Load BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
        "checkpoint = \"bert-base-uncased\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "id": "1d37f260",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.16.1\n",
            "4.41.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import transformers\n",
        "print(tf.__version__)\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "id": "0fdd17eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['TF_USE_LEGACY_KERAS'] = '1' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "id": "722485b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tf_keras\n",
        "adam = tf_keras.src.optimizers.Adam(learning_rate=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "id": "a2479b6c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "a2479b6c",
        "outputId": "9620ff12-cba4-476b-ac57-572e38226df6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100%|██████████| 600/600 [00:00<00:00, 1216.53 examples/s]\n",
            "Map: 100%|██████████| 150/150 [00:00<00:00, 1309.57 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 330s 4s/step - loss: 0.6599 - accuracy: 0.6550 - val_loss: 0.6693 - val_accuracy: 0.5800\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 333s 4s/step - loss: 0.6444 - accuracy: 0.6550 - val_loss: 0.6609 - val_accuracy: 0.5800\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 357s 5s/step - loss: 0.6392 - accuracy: 0.6550 - val_loss: 0.6515 - val_accuracy: 0.5800\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 361s 5s/step - loss: 0.6220 - accuracy: 0.6550 - val_loss: 0.6394 - val_accuracy: 0.5800\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 341s 5s/step - loss: 0.6109 - accuracy: 0.6550 - val_loss: 0.6193 - val_accuracy: 0.5800\n",
            "Fitting fold 1 is DONE!! Time: 1723.15s\n",
            "19/19 [==============================] - 25s 1s/step - loss: 0.6193 - accuracy: 0.5800\n",
            "19/19 [==============================] - 24s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100%|██████████| 600/600 [00:00<00:00, 1302.33 examples/s]\n",
            "Map: 100%|██████████| 150/150 [00:00<00:00, 1441.49 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 340s 5s/step - loss: 0.6754 - accuracy: 0.6250 - val_loss: 0.6218 - val_accuracy: 0.7000\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 336s 4s/step - loss: 0.6352 - accuracy: 0.6250 - val_loss: 0.5898 - val_accuracy: 0.7000\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 337s 4s/step - loss: 0.6071 - accuracy: 0.6250 - val_loss: 0.5543 - val_accuracy: 0.7000\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 336s 4s/step - loss: 0.5636 - accuracy: 0.6250 - val_loss: 0.5134 - val_accuracy: 0.7000\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 344s 5s/step - loss: 0.5164 - accuracy: 0.6250 - val_loss: 0.4661 - val_accuracy: 0.7000\n",
            "Fitting fold 2 is DONE!! Time: 1693.93s\n",
            "19/19 [==============================] - 26s 1s/step - loss: 0.4661 - accuracy: 0.7000\n",
            "19/19 [==============================] - 25s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100%|██████████| 600/600 [00:00<00:00, 1314.92 examples/s]\n",
            "Map: 100%|██████████| 150/150 [00:00<00:00, 1341.13 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 344s 5s/step - loss: 0.6582 - accuracy: 0.6367 - val_loss: 0.6295 - val_accuracy: 0.6533\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 332s 4s/step - loss: 0.6207 - accuracy: 0.6367 - val_loss: 0.5690 - val_accuracy: 0.6533\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 342s 5s/step - loss: 0.5619 - accuracy: 0.6683 - val_loss: 0.4951 - val_accuracy: 0.7267\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 340s 5s/step - loss: 0.4952 - accuracy: 0.7800 - val_loss: 0.4338 - val_accuracy: 0.8400\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 339s 5s/step - loss: 0.4368 - accuracy: 0.8567 - val_loss: 0.3700 - val_accuracy: 0.9067\n",
            "Fitting fold 3 is DONE!! Time: 1696.4s\n",
            "19/19 [==============================] - 25s 1s/step - loss: 0.3700 - accuracy: 0.9067\n",
            "19/19 [==============================] - 24s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100%|██████████| 600/600 [00:00<00:00, 1387.33 examples/s]\n",
            "Map: 100%|██████████| 150/150 [00:00<00:00, 1388.78 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 329s 4s/step - loss: 0.6483 - accuracy: 0.6400 - val_loss: 0.6402 - val_accuracy: 0.6400\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 327s 4s/step - loss: 0.6131 - accuracy: 0.6400 - val_loss: 0.5838 - val_accuracy: 0.6400\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 326s 4s/step - loss: 0.5608 - accuracy: 0.6417 - val_loss: 0.5230 - val_accuracy: 0.6467\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 326s 4s/step - loss: 0.4785 - accuracy: 0.6883 - val_loss: 0.4310 - val_accuracy: 0.8200\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 325s 4s/step - loss: 0.4061 - accuracy: 0.7900 - val_loss: 0.3864 - val_accuracy: 0.9467\n",
            "Fitting fold 4 is DONE!! Time: 1632.63s\n",
            "19/19 [==============================] - 25s 1s/step - loss: 0.3864 - accuracy: 0.9467\n",
            "19/19 [==============================] - 24s 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100%|██████████| 600/600 [00:00<00:00, 1456.45 examples/s]\n",
            "Map: 100%|██████████| 150/150 [00:00<00:00, 1339.23 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "75/75 [==============================] - 328s 4s/step - loss: 0.6387 - accuracy: 0.6433 - val_loss: 0.6171 - val_accuracy: 0.6267\n",
            "Epoch 2/5\n",
            "75/75 [==============================] - 329s 4s/step - loss: 0.5945 - accuracy: 0.6583 - val_loss: 0.5514 - val_accuracy: 0.7000\n",
            "Epoch 3/5\n",
            "75/75 [==============================] - 333s 4s/step - loss: 0.5281 - accuracy: 0.7167 - val_loss: 0.4721 - val_accuracy: 0.7800\n",
            "Epoch 4/5\n",
            "75/75 [==============================] - 333s 4s/step - loss: 0.4641 - accuracy: 0.8083 - val_loss: 0.3923 - val_accuracy: 0.8800\n",
            "Epoch 5/5\n",
            "75/75 [==============================] - 333s 4s/step - loss: 0.3934 - accuracy: 0.8733 - val_loss: 0.3374 - val_accuracy: 0.9267\n",
            "Fitting fold 5 is DONE!! Time: 1656.34s\n",
            "19/19 [==============================] - 25s 1s/step - loss: 0.3374 - accuracy: 0.9267\n",
            "19/19 [==============================] - 24s 1s/step\n",
            "Mean Accuracy: 0.8426666666666666\n",
            "Mean Precision: 0.8755966321061408\n",
            "Mean Recall: 0.8426666666666666\n",
            "Mean F1 Score: 0.8171055918549854\n"
          ]
        }
      ],
      "source": [
        "# this here uses manual cross validation!\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import datasets\n",
        "import time\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 5\n",
        "N_SPLITS = 5\n",
        "\n",
        "# Shuffle and split data into N_SPLITS folds\n",
        "indices = np.arange(len(X))\n",
        "np.random.shuffle(indices)\n",
        "folds = np.array_split(indices, N_SPLITS)\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "all_val_preds = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1s = []\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['hyp'], truncation=True, padding='max_length', max_length=100)\n",
        "\n",
        "def order(inp):\n",
        "    data = list(inp.values())\n",
        "    return {\n",
        "        'input_ids': tf.convert_to_tensor(data[1], dtype=tf.int32),\n",
        "        'token_type_ids': tf.convert_to_tensor(data[2], dtype=tf.int32),\n",
        "        'attention_mask': tf.convert_to_tensor(data[3], dtype=tf.int32),\n",
        "    }, data[0]\n",
        "# changed from optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5), to without legacy\n",
        "# bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=1)\n",
        "# bert_model.compile(\n",
        "#     # optimizer=Adam,\n",
        "#     loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "for i in range(N_SPLITS):\n",
        "    # Reset model for each fold\n",
        "    bert_model = TFBertForSequenceClassification.from_pretrained(checkpoint, num_labels=1)\n",
        "    \n",
        "    # Compile the model with appropriate loss function and optimizer\n",
        "    bert_model.compile(\n",
        "        # first try out lr of 1e-6, then 1e-5, then 1e-4\n",
        "        # optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-6),\n",
        "        optimizer=adam,\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    # the code below resets model, and I might try it out? maybe idk\n",
        "    # Prepare training and validation indices\n",
        "    val_indices = folds[i]\n",
        "    train_indices = np.hstack([folds[j] for j in range(N_SPLITS) if j != i])\n",
        "\n",
        "    # Split the data\n",
        "    X_train2, X_val = X[train_indices], X[val_indices]\n",
        "    y_train2, y_val = y[train_indices], y[val_indices]\n",
        "\n",
        "    # Create Pandas DataFrames\n",
        "    X_train2_df = pd.DataFrame({'hyp': X_train2, 'label': y_train2})\n",
        "    X_val_df = pd.DataFrame({'hyp': X_val, 'label': y_val})\n",
        "\n",
        "    # Convert to HuggingFace Datasets\n",
        "    df_train = datasets.Dataset.from_pandas(X_train2_df)\n",
        "    df_val = datasets.Dataset.from_pandas(X_val_df)\n",
        "    dataset = datasets.DatasetDict({'train': df_train, 'val': df_val})\n",
        "\n",
        "    # Tokenize the datasets\n",
        "    tokenized_datasets_mapped = dataset.map(tokenize_function, batched=True, batch_size=BATCH_SIZE, remove_columns=['hyp'])\n",
        "\n",
        "    # Convert to TensorFlow Datasets\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(tokenized_datasets_mapped['train'][:])\n",
        "    train_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\n",
        "    train_dataset = train_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices(tokenized_datasets_mapped['val'][:])\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "    val_dataset = val_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Train the model\n",
        "    start = time.time()\n",
        "    bert_model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "    end = time.time()\n",
        "    elapsed_time = round(end - start, 2)\n",
        "    print(f'Fitting fold {i+1} is DONE!! Time: {elapsed_time}s')\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluated = bert_model.evaluate(val_dataset)\n",
        "    val_preds = bert_model.predict(val_dataset).logits\n",
        "#     val_preds = tf.nn.softmax(val_preds, axis=1).numpy()[:, 1]  # Probability of class 1, 1 try\n",
        "    # val_preds = tf.nn.sigmoid(val_preds).numpy().squeeze()[:, 1] # 2nd attempt, also i might need try out\n",
        "    # using a [:, 0] instead?\n",
        "    # Apply sigmoid activation\n",
        "    val_preds = tf.nn.sigmoid(val_preds).numpy()\n",
        "\n",
        "    # Check if val_preds has more than one dimension\n",
        "    if val_preds.ndim > 1:\n",
        "        val_preds = val_preds.squeeze()\n",
        "        # Ensure that there are at least two dimensions to index\n",
        "        if val_preds.ndim > 1:\n",
        "            val_preds = val_preds[:, 1]\n",
        "        else:\n",
        "            # Handle case where squeezing resulted in a single dimension\n",
        "            val_preds = val_preds.flatten()\n",
        "    else:\n",
        "        val_preds = val_preds.flatten()\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_val, val_preds.round(), average='weighted')\n",
        "    acc = accuracy_score(y_val, val_preds.round())\n",
        "\n",
        "    all_val_preds.append(val_preds)\n",
        "    accuracies.append(acc)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1s.append(f1)\n",
        "\n",
        "# Calculate and print average metrics\n",
        "print(f'Mean Accuracy: {np.mean(accuracies)}')\n",
        "print(f'Mean Precision: {np.mean(precisions)}')\n",
        "print(f'Mean Recall: {np.mean(recalls)}')\n",
        "print(f'Mean F1 Score: {np.mean(f1s)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "id": "5da4f0f2",
      "metadata": {
        "id": "5da4f0f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 375/375 [00:00<00:00, 1449.34 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Convert to TensorFlow Datasets\n",
        "def order_final(example):\n",
        "    return {\n",
        "        'input_ids': tf.convert_to_tensor(example['input_ids'], dtype=tf.int32),\n",
        "        'attention_mask': tf.convert_to_tensor(example['attention_mask'], dtype=tf.int32),\n",
        "        'token_type_ids': tf.convert_to_tensor(example['token_type_ids'], dtype=tf.int32),\n",
        "    }, tf.convert_to_tensor(example['label'], dtype=tf.int32)\n",
        "\n",
        "\n",
        "# final two datasets\n",
        "ag_X, ag_y = final_ag_pg['hyp'], final_ag_pg['label']\n",
        "# ag_X, ag_y = final_ag_dm['hyp'], final_ag_dm['label']\n",
        "# ag_X, ag_y = final_ag_mt['hyp'], final_ag_mt['label']\n",
        "\n",
        "# ag_X, ag_y = final_aw_pg['hyp'], final_aw_pg['label']\n",
        "# ag_X, ag_y = final_aw_dm['hyp'], final_aw_dm['label']\n",
        "# ag_X, ag_y = final_aw_mt['hyp'], final_aw_mt['label']\n",
        "\n",
        "# Create Pandas DataFrames\n",
        "final_df = pd.DataFrame({'hyp': ag_X, 'label': ag_y})\n",
        "\n",
        "# Convert to HuggingFace Datasets\n",
        "final_df2 = datasets.Dataset.from_pandas(final_df)\n",
        "dataset = datasets.DatasetDict({'final': final_df2})\n",
        "\n",
        "# Tokenize the datasets\n",
        "tokenized_datasets_mapped = dataset.map(tokenize_function, batched=True, batch_size=BATCH_SIZE, remove_columns=['hyp'])\n",
        "\n",
        "# Convert to TensorFlow Datasets\n",
        "final_dataset = tf.data.Dataset.from_tensor_slices(tokenized_datasets_mapped['final'][:])\n",
        "final_dataset = final_dataset.batch(BATCH_SIZE)\n",
        "final_dataset = final_dataset.map(order_final, num_parallel_calls=tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "id": "94f62e4d",
      "metadata": {
        "id": "94f62e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 61s 1s/step\n"
          ]
        }
      ],
      "source": [
        "# my attempt failed for final dataset\n",
        "# evaluated = model.evaluate(final_dataset)\n",
        "final_preds = bert_model.predict(final_dataset).logits\n",
        "final_preds = tf.nn.sigmoid(final_preds).numpy()\n",
        "# Check if val_preds has more than one dimension\n",
        "if final_preds.ndim > 1:\n",
        "    final_preds = final_preds.squeeze()\n",
        "    # Ensure that there are at least two dimensions to index\n",
        "    if final_preds.ndim > 1:\n",
        "        final_preds = final_preds[:, 1]\n",
        "    else:\n",
        "        # Handle case where squeezing resulted in a single dimension\n",
        "        final_preds = final_preds.flatten()\n",
        "else:\n",
        "    final_preds = final_preds.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "id": "888e2def",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final aggregate accuracy BERT: 0.6426666666666667\n"
          ]
        }
      ],
      "source": [
        "final_preds_binary = [1 if x > 0.5 else 0 for x in final_preds]\n",
        "# final_preds_mean = np.mean(final_preds, axis=0)\n",
        "# final_labels = (final_preds_mean >= 0.5).astype(int)\n",
        "print(f'final aggregate accuracy BERT: {accuracy_score(final_preds_binary, ag_y)}')\n",
        "\n",
        "# train = pg_rd,final_val = ag_pg: 0.6533333333333333\n",
        "# train = pg_rd,final_val = ag_dm: 0.517\n",
        "# train = pg_rd,final_val = ag_mt: 0.537\n",
        "# jsut using 0s = 0.598\n",
        "\n",
        "# train = pg_sr, final_val = ag_pg: 0.675\n",
        "# train = pg_sr, final_val = ag_dm: 0.506\n",
        "# train = pg_sr, final_val = ag_mt: 0.56\n",
        "\n",
        "# train = pg_rs, final_val = ag_pg: 0.\n",
        "# train = pg_rs, final_val = ag_dm: 0.\n",
        "# train = pg_rs, final_val = ag_mt: 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "id": "536fddf4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3502739"
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_preds_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "id": "0e99625c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all zeros BERT: 0.7413333333333333\n"
          ]
        }
      ],
      "source": [
        "all_zeros = [0 for x in final_preds]\n",
        "print(f'all zeros BERT: {accuracy_score(all_zeros, ag_y)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "id": "1e47d5cf",
      "metadata": {
        "id": "1e47d5cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(375, 375)"
            ]
          },
          "execution_count": 260,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# myset = set(final_preds)\n",
        "# print(myset)\n",
        "len(ag_y), len(final_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "4476a729",
      "metadata": {
        "id": "4476a729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8427\n",
            "Precision: 0.8756\n",
            "Recall: 0.8427\n",
            "F1 Score: 0.8171\n",
            "Final Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0]\n"
          ]
        }
      ],
      "source": [
        "# i guess right now the big question is, is there a point in using cross validation?\n",
        "# unless to get best hyper paramter, which i believe i can use some other library for that,\n",
        "# what is the point? chatgpt said training final model invovles just using only\n",
        "# train test split so...\n",
        "final_preds = np.mean(all_val_preds, axis=0)\n",
        "final_labels = (final_preds >= 0.5).astype(int)\n",
        "\n",
        "print(f'Accuracy: {np.mean(accuracies):.4f}')\n",
        "print(f'Precision: {np.mean(precisions):.4f}')\n",
        "print(f'Recall: {np.mean(recalls):.4f}')\n",
        "print(f'F1 Score: {np.mean(f1s):.4f}')\n",
        "print(f'Final Predictions: {final_labels}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "id": "033d55f1",
      "metadata": {
        "id": "033d55f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 375/375 [00:00<00:00, 1317.01 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 61s 1s/step\n",
            "Final aggregate accuracy BERT: 0.6426666666666667\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score\n",
        "import datasets\n",
        "\n",
        "# Ensure eager execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "# Create Pandas DataFrame without the index\n",
        "final_df = pd.DataFrame({'hyp': ag_X, 'label': ag_y})\n",
        "\n",
        "# Convert to HuggingFace Datasets\n",
        "final_df2 = datasets.Dataset.from_pandas(final_df)\n",
        "dataset = datasets.DatasetDict({'final': final_df2})\n",
        "\n",
        "# Initialize tokenizer (make sure you have the right model name)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the datasets\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example['hyp'], truncation=True, padding='max_length', max_length=100)\n",
        "\n",
        "tokenized_datasets_mapped = dataset.map(tokenize_function, batched=True, batch_size=BATCH_SIZE, remove_columns=['hyp'])\n",
        "\n",
        "# Use from_generator to create dataset with correct output signature\n",
        "# final_dataset = tf.data.Dataset.from_generator(\n",
        "#     lambda: iter(tokenized_datasets_mapped['final']),\n",
        "#     output_signature=(\n",
        "#         {\n",
        "#             'input_ids': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
        "#             'attention_mask': tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
        "#             'token_type_ids': tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "#         },\n",
        "#         tf.TensorSpec(shape=(), dtype=tf.int32)\n",
        "#     )\n",
        "# )\n",
        "final_dataset = tf.data.Dataset.from_tensor_slices(tokenized_datasets_mapped['final'][:])\n",
        "final_dataset = final_dataset.batch(BATCH_SIZE)\n",
        "final_dataset = final_dataset.map(order_final, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Evaluate the model\n",
        "final_preds = bert_model.predict(final_dataset).logits\n",
        "\n",
        "# Apply sigmoid to get probabilities and flatten the tensor\n",
        "final_preds = tf.nn.sigmoid(final_preds).numpy().squeeze()\n",
        "\n",
        "# If final_preds is still multidimensional, reduce it to a 1D array\n",
        "if final_preds.ndim > 1:\n",
        "    final_preds = final_preds[:, 0]\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(ag_y, final_preds.round())\n",
        "print(f'Final aggregate accuracy BERT: {accuracy}')\n",
        "\n",
        "# keep track of results here for now\n",
        "# for task pg, 0.645\n",
        "# for task dm, 0.453\n",
        "# for task mt, 0.486"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "id": "cf2983cc",
      "metadata": {
        "id": "cf2983cc"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# copy_of_predictions = list(predictions)\n",
        "# index = 0\n",
        "# for i in range(len(copy_of_predictions)):\n",
        "#     copy_of_predictions[i] = list(dict(copy_of_predictions[i]).values())\n",
        "# #     for key,value in copy_of_predictions[i].items():\n",
        "# #         copy_of_predictions[i][key] = list(value)\n",
        "\n",
        "# print(copy_of_predictions)\n",
        "# with open('mt_sr_160.json','w') as f:\n",
        "# #     f.write(copy_of_predictions)\n",
        "#     json.dump(copy_of_predictions, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "id": "2d24cd4c",
      "metadata": {
        "id": "2d24cd4c"
      },
      "outputs": [],
      "source": [
        "# kf.get_n_splits(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658504c4",
      "metadata": {
        "id": "658504c4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch_cuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
