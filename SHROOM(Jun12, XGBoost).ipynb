{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "# sns.set()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Graphics in retina format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/thesis_data_after\n",
    "# task PG, num_aug 16\n",
    "\n",
    "# just use sr, and rs 6/6\n",
    "pg_rd_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/pg_df_rd.csv'\n",
    "pg_ri_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/pg_df_ri.csv'\n",
    "pg_rs_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after/rs/pg_df_rs.csv'\n",
    "pg_sr_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after/sr/pg_df_sr.csv'\n",
    "\n",
    "pg_rd = pd.read_csv(pg_rd_path, encoding_errors='backslashreplace')\n",
    "pg_ri = pd.read_csv(pg_ri_path, encoding_errors='backslashreplace')\n",
    "pg_rs = pd.read_csv(pg_rs_path, encoding_errors='backslashreplace')\n",
    "pg_sr = pd.read_csv(pg_sr_path, encoding_errors='backslashreplace')\n",
    "\n",
    "# num_aug 160\n",
    "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/pg_df_rd.csv'\n",
    "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/pg_df_ri.csv'\n",
    "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after_160/rs/pg_df_rs.csv'\n",
    "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after_160/sr/pg_df_sr.csv'\n",
    "\n",
    "pg_rd_160 = pd.read_csv(path1, encoding_errors='backslashreplace')\n",
    "pg_ri_160 = pd.read_csv(path2, encoding_errors='backslashreplace')\n",
    "pg_rs_160 = pd.read_csv(path3, encoding_errors='backslashreplace')\n",
    "pg_sr_160 = pd.read_csv(path4, encoding_errors='backslashreplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task DM 16\n",
    "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/dm_df_rd.csv'\n",
    "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/dm_df_ri.csv'\n",
    "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after/rs/dm_df_rs.csv'\n",
    "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after/sr/dm_df_sr.csv'\n",
    "\n",
    "dm_rd = pd.read_csv(path1, encoding_errors='backslashreplace')\n",
    "dm_ri = pd.read_csv(path2, encoding_errors='backslashreplace')\n",
    "dm_rs = pd.read_csv(path3, encoding_errors='backslashreplace')\n",
    "dm_sr = pd.read_csv(path4, encoding_errors='backslashreplace')\n",
    "\n",
    "# 160\n",
    "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/rd/dm_df_rd.csv'\n",
    "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/ri/dm_df_ri.csv'\n",
    "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after_160/rs/dm_df_rs.csv'\n",
    "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after_160/sr/dm_df_sr.csv'\n",
    "\n",
    "dm_rd_160 = pd.read_csv(path1, encoding_errors='backslashreplace')\n",
    "dm_ri_160 = pd.read_csv(path2, encoding_errors='backslashreplace')\n",
    "dm_rs_160 = pd.read_csv(path3, encoding_errors='backslashreplace')\n",
    "dm_sr_160 = pd.read_csv(path4, encoding_errors='backslashreplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task MT 16\n",
    "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/rd/mt_df_rd.csv'\n",
    "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after/ri/mt_df_ri.csv'\n",
    "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after/rs/mt_df_rs.csv'\n",
    "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after/sr/mt_df_sr.csv'\n",
    "\n",
    "mt_rd = pd.read_csv(path1, encoding_errors='backslashreplace')\n",
    "mt_ri = pd.read_csv(path2, encoding_errors='backslashreplace')\n",
    "mt_rs = pd.read_csv(path3, encoding_errors='backslashreplace')\n",
    "mt_sr = pd.read_csv(path4, encoding_errors='backslashreplace')\n",
    "\n",
    "# 160\n",
    "path1 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/rd/mt_df_rd.csv'\n",
    "path2 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_after_160/ri/mt_df_ri.csv'\n",
    "path3 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after_160/rs/mt_df_rs.csv'\n",
    "path4 = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/eda_nlp-20240601T173748Z-001/eda_nlp/thesis_data_lemmatized_after_160/sr/mt_df_sr.csv'\n",
    "\n",
    "mt_rd_160 = pd.read_csv(path1, encoding_errors='backslashreplace')\n",
    "mt_ri_160 = pd.read_csv(path2, encoding_errors='backslashreplace')\n",
    "mt_rs_160 = pd.read_csv(path3, encoding_errors='backslashreplace')\n",
    "mt_sr_160 = pd.read_csv(path4, encoding_errors='backslashreplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>model</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john john one</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>john ann like</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>john john one</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>john ann like</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john john one</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>john ann like</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>john one</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>john ann</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>john john one</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>john ann like</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>dont money buy dictionary</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>money buy dictionary</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>dont money buy dictionary</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>buy dictionary</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>dont money buy dictionary</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>money buy dictionary</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>dont money buy dictionary</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>money buy dictionary</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7853</th>\n",
       "      <td>dont money buy dictionary</td>\n",
       "      <td>either</td>\n",
       "      <td></td>\n",
       "      <td>money buy dictionary</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7854 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            hyp     ref src                   tgt model  \\\n",
       "0                 john john one  either             john ann like         \n",
       "1                 john john one  either             john ann like         \n",
       "2                 john john one  either             john ann like         \n",
       "3                      john one  either                  john ann         \n",
       "4                 john john one  either             john ann like         \n",
       "...                         ...     ...  ..                   ...   ...   \n",
       "7849  dont money buy dictionary  either      money buy dictionary         \n",
       "7850  dont money buy dictionary  either            buy dictionary         \n",
       "7851  dont money buy dictionary  either      money buy dictionary         \n",
       "7852  dont money buy dictionary  either      money buy dictionary         \n",
       "7853  dont money buy dictionary  either      money buy dictionary         \n",
       "\n",
       "      label  p(Hallucination) Unnamed: 7  \n",
       "0         1               1.0             \n",
       "1         1               1.0             \n",
       "2         1               1.0             \n",
       "3         1               1.0             \n",
       "4         1               1.0             \n",
       "...     ...               ...        ...  \n",
       "7849      0               0.0             \n",
       "7850      0               0.0             \n",
       "7851      0               0.0             \n",
       "7852      0               0.0             \n",
       "7853      0               0.0             \n",
       "\n",
       "[7854 rows x 8 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pg_rd = pg_rd.dropna(how=\"any\", axis=1)\n",
    "pg_rd = pg_rd.fillna('')\n",
    "pg_ri = pg_ri.fillna('')\n",
    "pg_rs = pg_rs.fillna('')\n",
    "pg_sr = pg_sr.fillna('')\n",
    "\n",
    "dm_rd = dm_rd.fillna('')\n",
    "dm_ri = dm_ri.fillna('')\n",
    "dm_rs = dm_rs.fillna('')\n",
    "dm_sr = dm_sr.fillna('')\n",
    "\n",
    "mt_rd = mt_rd.fillna('')\n",
    "mt_ri = mt_ri.fillna('')\n",
    "mt_rs = mt_rs.fillna('')\n",
    "mt_sr = mt_sr.fillna('')\n",
    "\n",
    "pg_rd_160 = pg_rd_160.fillna('')\n",
    "pg_ri_160 = pg_ri_160.fillna('')\n",
    "pg_rs_160 = pg_rs_160.fillna('')\n",
    "pg_sr_160 = pg_sr_160.fillna('')\n",
    "\n",
    "dm_rd_160 = dm_rd_160.fillna('')\n",
    "dm_ri_160 = dm_ri_160.fillna('')\n",
    "dm_rs_160 = dm_rs_160.fillna('')\n",
    "dm_sr_160 = dm_sr_160.fillna('')\n",
    "\n",
    "mt_rd_160 = mt_rd_160.fillna('')\n",
    "mt_ri_160 = mt_ri_160.fillna('')\n",
    "mt_rs_160 = mt_rs_160.fillna('')\n",
    "mt_sr_160 = mt_sr_160.fillna('')\n",
    "# drop na just deleted the model column i think\n",
    "mt_rd_160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class count: 4158\n",
      "Minority class count: 1092\n",
      "label\n",
      "1    500\n",
      "0    500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Separate majority and minority classes\n",
    "# change here the dataset_name\n",
    "# before_balance_dataset = dm_sr_160\n",
    "before_balance_dataset = pg_sr_160\n",
    "# before_balance_dataset = mt_sr_160\n",
    "df_majority = before_balance_dataset[before_balance_dataset.label == 0]\n",
    "df_minority = before_balance_dataset[before_balance_dataset.label == 1]\n",
    "\n",
    "# Check the counts\n",
    "print(\"Majority class count:\", len(df_majority))\n",
    "print(\"Minority class count:\", len(df_minority))\n",
    "\n",
    "# Downsample majority class if there are enough samples\n",
    "if len(df_majority) >= 500 and len(df_minority) >= 500:\n",
    "    df_majority_downsampled = resample(df_majority, \n",
    "                                       replace=False,    # sample without replacement\n",
    "                                       n_samples=500,   # to match minority class\n",
    "                                       random_state=42)  # reproducible results\n",
    "    df_minority_downsampled = resample(df_minority, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=500,   # to match minority class\n",
    "                                        random_state=42)\n",
    "\n",
    "    # Combine minority class with downsampled majority class\n",
    "    df_balanced = pd.concat([df_majority_downsampled, df_minority_downsampled])\n",
    "else:\n",
    "    raise ValueError(\"Not enough samples in one of the classes to downsample to 500\")\n",
    "\n",
    "# Shuffle the resulting DataFrame\n",
    "balanced_dataset = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(balanced_dataset['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agg column with tgt + hyp\n",
    "balanced_dataset[\"agg\"] = \"hyp: \" + balanced_dataset[\"hyp\"] + \\\n",
    "    \" tgt: \" + balanced_dataset[\"tgt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset before data aug\n",
    "# X, y = pg_df['hyp'], pg_df['label']\n",
    "# X, y = dm_df['hyp'], dm_df['label']\n",
    "# X, y = mt_df['hyp'], mt_df['label']\n",
    "\n",
    "# task PG\n",
    "# X, y = pg_rd[['hyp','tgt']] , pg_rd['label']\n",
    "# X, y = pg_ri[['hyp','tgt']] , pg_ri['label']\n",
    "# X, y = pg_rs[['hyp','tgt']] , pg_rs['label']\n",
    "# X, y = pg_sr[['hyp','tgt']] , pg_sr['label']\n",
    "# task DM\n",
    "# X, y = dm_rd[['hyp','tgt']] , dm_rd['label']\n",
    "# X, y = dm_ri[['hyp','tgt']], dm_ri['label']\n",
    "# X, y = dm_rs[['hyp','tgt']] , dm_rs['label']\n",
    "# X, y = dm_sr[['hyp','tgt']] , dm_sr['label']\n",
    "# task MT\n",
    "# X, y = mt_rd[['hyp','tgt']] , mt_rd['label']\n",
    "# X, y = mt_ri[['hyp','tgt']] , mt_ri['label']\n",
    "# X, y = mt_rs[['hyp','tgt']] , mt_rs['label']\n",
    "# X, y = mt_sr[['hyp','tgt']] , mt_sr['label']\n",
    "\n",
    "# X, y = df['hyp'], df['label']\n",
    "# one way of getting label where task is DM, df.loc[df['task'] == 'DM', 'label']\n",
    "# X, y = df[df['task'] == 'PG']['hyp'], df[df['task'] == 'PG']['label']\n",
    "\n",
    "# task PG\n",
    "# X, y = pg_rd_160[['hyp','tgt']] , pg_rd_160['label']\n",
    "# X, y = pg_ri_160[['hyp','tgt']] , pg_ri_160['label']\n",
    "# X, y = pg_rs_160[['hyp','tgt']] , pg_rs_160['label']\n",
    "# X, y = pg_sr_160[['hyp','tgt']] , pg_sr_160['label']\n",
    "# pg_sr_160 for some reason does not have any tgt values in all rows??\n",
    "\n",
    "# task DM\n",
    "# X, y = dm_rd_160[['hyp','tgt']] , dm_rd_160['label']\n",
    "# X, y = dm_ri_160[['hyp','tgt']] , dm_ri_160['label']\n",
    "# X, y = dm_rs_160[['hyp','tgt']] , dm_rs_160['label']\n",
    "# X, y = dm_sr_160[['hyp','tgt']] , dm_sr_160['label']\n",
    "X, y = balanced_dataset['agg'] , balanced_dataset['label']\n",
    "# dm_sr_160 had basically the same amount of entrie of class 0 and 1\n",
    "# Counter({0: 4158, 1: 3738}), so i skipped making balanced dataset\n",
    "# task MT\n",
    "# X, y = mt_rd_160[['hyp','tgt']] , mt_rd_160['label']\n",
    "# X, y = mt_ri_160[['hyp','tgt']] , mt_ri_160['label']\n",
    "# X, y = mt_rs_160[['hyp','tgt']] , mt_rs_160['label']\n",
    "# X, y = mt_sr_160[['hyp','tgt']] , mt_sr_160['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 500, 0: 500})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "# y.value_counts()\n",
    "counter = collections.Counter(y)\n",
    "counter\n",
    "# just as reference, pg_rd from thesis_data_after directory has 750 entry in total\n",
    "# 480 is 0 and 270 is 1\n",
    "# but pg_rs after lemmatizing and using 160 data aug,\n",
    "# total: about 5200, 0 is 4158 and 1is 1092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example text url email example example com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Make text lowercase, remove text in square brackets, remove links, remove punctuation,\n",
    "    and remove words containing numbers.\n",
    "    '''\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(rf'[{re.escape(string.punctuation)}]', ' ', text)\n",
    "    \n",
    "    # Remove new lines\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_data(text):\n",
    "    text = clean_text(text)  # Clean punctuation, URLs, and so on\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    # Lemmatize all the words in the sentence\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "example_text = \"This is an example text with a URL: http://example.com and an email: example@example.com.\"\n",
    "cleaned_text = preprocess_data(example_text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# paths to final test data\n",
    "final_ag_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/final_test_data/test.model-agnostic.json'\n",
    "final_aw_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/final_test_data/test.model-agnostic.json'\n",
    "\n",
    "final_ag_df = pd.read_json(final_ag_path, encoding_errors='backslashreplace')\n",
    "final_aw_df = pd.read_json(final_aw_path, encoding_errors='backslashreplace')\n",
    "final_ag_df[\"label\"] = final_ag_df[\"label\"].map({\"Hallucination\":1, \"Not Hallucination\":0})\n",
    "final_aw_df[\"label\"] = final_aw_df[\"label\"].map({\"Hallucination\":1, \"Not Hallucination\":0})\n",
    "# perform preprocessing on final_df AND split it based on tasks!\n",
    "columns = ['hyp','src','tgt'] # exclude task\n",
    "for x in columns:\n",
    "    final_ag_df[x] = final_ag_df[x].apply(preprocess_data)\n",
    "for x in columns:\n",
    "    final_aw_df[x] = final_aw_df[x].apply(preprocess_data)\n",
    "final_ag_pg = final_ag_df[final_ag_df['task'] == 'PG']\n",
    "final_ag_dm = final_ag_df[final_ag_df['task'] == 'DM']\n",
    "final_ag_mt = final_ag_df[final_ag_df['task'] == 'MT']\n",
    "\n",
    "final_aw_pg = final_aw_df[final_aw_df['task'] == 'PG']\n",
    "final_aw_dm = final_aw_df[final_aw_df['task'] == 'DM']\n",
    "final_aw_mt = final_aw_df[final_aw_df['task'] == 'MT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFRobertaForSequenceClassification\n",
    "\n",
    "# Load tokenizer and model\n",
    "checkpoint = 'FacebookAI/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(checkpoint, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_pipe = Pipeline([\n",
    "                ('bow', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('model', xgb.XGBClassifier(\n",
    "                    learning_rate=0.1,\n",
    "                    max_depth=7,\n",
    "                    n_estimators=80,\n",
    "                    use_label_encoder=False,\n",
    "                    eval_metric='auc'))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score For Test Data: -> 0.89\n",
      "Confusion Matrix Score For Test Data:\n",
      " [[80 20]\n",
      " [ 2 98]]\n",
      "xgboost Accuracy is -> 0.89\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline with the data\n",
    "xgb_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_pipe.predict(X_test)\n",
    "# y_pred_train = pipe.predict(X_train)\n",
    "\n",
    "# print('Train: {}'.format(accuracy_score(y_train, y_pred_train)))\n",
    "print(f'Accuracy Score For Test Data: -> {round(accuracy_score(y_test, y_pred),2)}')\n",
    "print(f'Confusion Matrix Score For Test Data:\\n {confusion_matrix(y_test, y_pred)}')\n",
    "# calculate the accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'xgboost Accuracy is -> {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score For final Data: -> 0.51\n",
      "Confusion Matrix Score For final Data:\n",
      " [[157 121]\n",
      " [ 62  35]]\n",
      "xgboost Accuracy is -> 0.51\n"
     ]
    }
   ],
   "source": [
    "final_dataset = final_ag_pg\n",
    "# final_dataset = final_ag_dm\n",
    "# final_dataset = final_ag_mt\n",
    "final_dataset[\"agg\"] = \"hyp: \" + final_dataset[\"hyp\"] + \\\n",
    "    \" tgt: \" + final_dataset[\"tgt\"]\n",
    "X_final, y_final = final_dataset['agg'], final_dataset['label']\n",
    "\n",
    "\n",
    "final_pred = xgb_pipe.predict(X_final)\n",
    "# print('Train: {}'.format(accuracy_score(y_train, final_pred_train)))\n",
    "print(f'Accuracy Score For final Data: -> {round(accuracy_score(y_final, final_pred),2)}')\n",
    "print(f'Confusion Matrix Score For final Data:\\n {confusion_matrix(y_final, final_pred)}')\n",
    "# calculate the accuracy\n",
    "acc = accuracy_score(y_final, final_pred)\n",
    "print(f'xgboost Accuracy is -> {round(acc,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Confusion Matrix:\n",
      " [[ 96   4]\n",
      " [  0 100]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.96      1.00      0.98       100\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.98      0.98      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n",
      "\n",
      "Best Accuracy: 0.98\n",
      "Best Confusion Matrix:\n",
      " [[ 96   4]\n",
      " [  0 100]]\n",
      "Best Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       100\n",
      "           1       0.96      1.00      0.98       100\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.98      0.98      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Vectorizing the text data\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Initializing and training the XGBoost model\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_vect, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = xgb.predict(X_test_vect)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Hyperparameter Tuning with Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_vect, y_train)\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_test_vect)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Best Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"Best Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_final_vect = vectorizer.transform(X_final)\n",
    "\n",
    "# y_pred = best_xgb.predict(X_final_vect)\n",
    "# print(\"Best Accuracy:\", accuracy_score(y_pred, y_final))\n",
    "# print(\"Best Confusion Matrix:\\n\", confusion_matrix(y_pred, y_final))\n",
    "# print(\"Best Classification Report:\\n\", classification_report(y_pred, y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29                          hyp: important uranium tgt: \n",
       "535    hyp: practice cannot bear eu behalf country tgt: \n",
       "695                     hyp: right always play off tgt: \n",
       "557    hyp: young fannie merritt farmer need hope enc...\n",
       "836       hyp: sentence removed consider important tgt: \n",
       "                             ...                        \n",
       "106                             hyp: gas pedal air tgt: \n",
       "270    hyp: rationale important achievement european ...\n",
       "860            hyp: clear european union inclusive tgt: \n",
       "435    hyp: financial support get up and go project i...\n",
       "102                    hyp: know th know wednesday tgt: \n",
       "Name: agg, Length: 800, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 4634.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset = datasets.Dataset.from_pandas(balanced_dataset)\n",
    "BATCH_SIZE=8\n",
    "# Define the tokenization function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['agg'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "# Tokenize the dataset\n",
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets_mapped = dataset.map(tokenize_function, batched=True, batch_size=BATCH_SIZE, remove_columns=['hyp','tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import tensorflow as tf\n",
    "\n",
    "# Extract embeddings function\n",
    "def extract_embeddings(inputs):\n",
    "    input_ids = tf.convert_to_tensor(inputs['input_ids'], dtype=tf.int32)\n",
    "    attention_mask = tf.convert_to_tensor(inputs['attention_mask'], dtype=tf.int32)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states[-1]\n",
    "    return hidden_states[:, 0, :].numpy()\n",
    "\n",
    "# i was thinking of splitting embeddings or dataset to train and test but...maybe laters\n",
    "embeddings = extract_embeddings(tokenized_datasets_mapped)\n",
    "# embeddings2 = extract_embeddings(tokenized_datasets_mapped)\n",
    "# embeddings3 = extract_embeddings(tokenized_datasets_mapped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "# data = pd.DataFrame({\n",
    "#     'hyp': ['sample text 1', 'sample text 2', 'sample text 3'],\n",
    "#     'label': [0, 1, 0]\n",
    "# })\n",
    "\n",
    "# X = data['hyp']\n",
    "# y = data['label']\n",
    "# Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# def get_embeddings(texts):\n",
    "#     inputs = tokenizer(texts, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
    "#     outputs = model(**inputs)\n",
    "#     return outputs.hidden_states[:, 0, :].numpy()\n",
    "\n",
    "# Get embeddings for train and test sets\n",
    "# X_train_embeddings = get_embeddings(X_train.tolist())\n",
    "# X_test_embeddings = get_embeddings(X_test.tolist())\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(embeddings, y_train)\n",
    "\n",
    "# # Predictions and evaluation\n",
    "# y_pred = xgb.predict(embeddings)\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Hyperparameter Tuning with Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(embeddings, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 562/562 [00:00<00:00, 3240.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# change this place to change final_dataset\n",
    "# copy_final_dataset = final_ag_pg\n",
    "# copy_final_dataset = final_ag_dm\n",
    "copy_final_dataset = final_ag_mt\n",
    "copy_final_dataset[\"agg\"] = \"hyp: \" + copy_final_dataset[\"hyp\"] + \\\n",
    "    \" tgt: \" + copy_final_dataset[\"tgt\"] + \\\n",
    "    \" src: \" + copy_final_dataset[\"src\"]\n",
    "X_final, y_final = copy_final_dataset['agg'], copy_final_dataset['label']\n",
    "final_dataset = datasets.Dataset.from_pandas(copy_final_dataset)\n",
    "\n",
    "\n",
    "final_tokenized = final_dataset.map(tokenize_function, batched=True, batch_size=BATCH_SIZE, remove_columns=['hyp','tgt'])\n",
    "final_embeddings = extract_embeddings(final_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_xgb \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      2\u001b[0m y_pred_best \u001b[38;5;241m=\u001b[39m best_xgb\u001b[38;5;241m.\u001b[39mpredict(final_embeddings)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_final, y_pred_best))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(final_embeddings)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_final, y_pred_best))\n",
    "print(\"Best Confusion Matrix:\\n\", confusion_matrix(y_final, y_pred_best))\n",
    "print(\"Best Classification Report:\\n\", classification_report(y_final, y_pred_best))\n",
    "\n",
    "# dm on pg = 0.64\n",
    "# dm on dm = 0.560\n",
    "# dm on mt = 0.559\n",
    "\n",
    "# pg on pg = 0.407\n",
    "# pg on dm = 0.\n",
    "# pg on mt = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.40747330960854095\n",
      "Best Confusion Matrix:\n",
      " [[ 40 296]\n",
      " [ 37 189]]\n",
      "Best Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.12      0.19       336\n",
      "           1       0.39      0.84      0.53       226\n",
      "\n",
      "    accuracy                           0.41       562\n",
      "   macro avg       0.45      0.48      0.36       562\n",
      "weighted avg       0.47      0.41      0.33       562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_xgb.predict(final_embeddings)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_final, y_pred_best))\n",
    "print(\"Best Confusion Matrix:\\n\", confusion_matrix(y_final, y_pred_best))\n",
    "print(\"Best Classification Report:\\n\", classification_report(y_final, y_pred_best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
