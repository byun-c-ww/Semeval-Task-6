{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "# sns.set()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Graphics in retina format are more sharp and legible\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    295\n",
      "1    206\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('data/val.model-aware.v2.json')\n",
    "df[\"label\"] = df[\"label\"].map({\"Hallucination\":1, \"Not Hallucination\":0})\n",
    "\n",
    "df = df.dropna(how=\"any\", axis=1)\n",
    "df.head()\n",
    "\n",
    "print(df['label'].value_counts())\n",
    "# training using original, 0 = 295, 1 = 206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example text url email example example com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Make text lowercase, remove text in square brackets, remove links, remove punctuation,\n",
    "    and remove words containing numbers.\n",
    "    '''\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(rf'[{re.escape(string.punctuation)}]', ' ', text)\n",
    "    \n",
    "    # Remove new lines\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_data(text):\n",
    "    text = clean_text(text)  # Clean punctuation, URLs, and so on\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    # Lemmatize all the words in the sentence\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "example_text = \"This is an example text with a URL: http://example.com and an email: example@example.com.\"\n",
    "cleaned_text = preprocess_data(example_text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['hyp','src','tgt'] # exclude task\n",
    "for x in columns:\n",
    "    df[x] = df[x].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['labels'], axis=1)\n",
    "dm_df = df[df['task'] == 'DM']\n",
    "mt_df = df[df['task'] == 'MT']\n",
    "pg_df = df[df['task'] == 'PG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p(Hallucination)\n",
       "1.0    35\n",
       "0.0    31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data with scores with either a 0 or 1\n",
    "dm_df_highscore = dm_df[dm_df['p(Hallucination)'].isin([0.0, 1.0])]\n",
    "pg_df_highscore = pg_df[pg_df['p(Hallucination)'].isin([0.0, 1.0])]\n",
    "mt_df_highscore = mt_df[mt_df['p(Hallucination)'].isin([0.0, 1.0])]\n",
    "dm_df_highscore['p(Hallucination)'].value_counts()\n",
    "# dm_df_highscore, 1.0 = 35, 0.0 = 31\n",
    "# pg_df_highscore['p(Hallucination)'].value_counts()\n",
    "# pg_df_highscore, 0.0 = 43, 1.0 = 5\n",
    "# mt_df_highscore['p(Hallucination)'].value_counts()\n",
    "# mt_df_highscore, 0.0 = 29, 1.0 = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>debate friday vote later date kept per agenda</td>\n",
       "      <td>src</td>\n",
       "      <td>propose therefore keep arrangement per agenda ...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>iraq become prominent international agenda pas...</td>\n",
       "      <td>src</td>\n",
       "      <td>past week iraq figured prominently minister sa...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>achievement enlargement historic</td>\n",
       "      <td>src</td>\n",
       "      <td>enlargement accomplishment historic significance</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>eurobonds example second one</td>\n",
       "      <td>src</td>\n",
       "      <td>second example relates eurobonds</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>mr doyle want ask supplementary question</td>\n",
       "      <td>src</td>\n",
       "      <td>wish pose supplementary question mr doyle</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>clear europe inclusive</td>\n",
       "      <td>src</td>\n",
       "      <td>parity clear signal inclusive europe</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>want tell mr colom know win</td>\n",
       "      <td>src</td>\n",
       "      <td>mr president like tell mr colom naval indeed k...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>clear case</td>\n",
       "      <td>src</td>\n",
       "      <td>already clear</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>question surrounding eurostat raised two year</td>\n",
       "      <td>src</td>\n",
       "      <td>would draw attention fact question surrounding...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>fact show make worse</td>\n",
       "      <td>src</td>\n",
       "      <td>exacerbate fact situation showing</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>two different signal sent</td>\n",
       "      <td>src</td>\n",
       "      <td>allows u send two different signal</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>erdf could used improve energy efficiency</td>\n",
       "      <td>src</td>\n",
       "      <td>possibility using erdf energy efficiency progr...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>world need conflict moment</td>\n",
       "      <td>src</td>\n",
       "      <td>would end saying world acute need conflict</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>envelope brought back</td>\n",
       "      <td>src</td>\n",
       "      <td>brings back envelope</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>good hunting practice important</td>\n",
       "      <td>src</td>\n",
       "      <td>clear good hunting practice crucial</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>think organically grown food better convention...</td>\n",
       "      <td>src</td>\n",
       "      <td>believe organic food automatically healthier b...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>food labelling used guide good diet</td>\n",
       "      <td>src</td>\n",
       "      <td>lastly stated food labelling never manual good...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>drug addicted person reminded letter</td>\n",
       "      <td>src</td>\n",
       "      <td>letter reminded drug addict denial addicted su...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>foreign policy union based importance relation...</td>\n",
       "      <td>src</td>\n",
       "      <td>absolutely doubt transatlantic relation essent...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>thing considered voting referendum</td>\n",
       "      <td>src</td>\n",
       "      <td>seriously consider thing deciding way vote ref...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>able consumed</td>\n",
       "      <td>src</td>\n",
       "      <td>yet eminently fit consumption</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>believe good idea use crude tool issue</td>\n",
       "      <td>src</td>\n",
       "      <td>belief incorrect use crude tool common europea...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>method used commission resulted legal problem ...</td>\n",
       "      <td>src</td>\n",
       "      <td>succeeded overcoming certain legal complicatio...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>amendment regulation implemented immediately d...</td>\n",
       "      <td>src</td>\n",
       "      <td>make appropriate decision today office begin i...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>issue need tackled quickly possible</td>\n",
       "      <td>src</td>\n",
       "      <td>need tackle issue matter urgency</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>good job role european parliament</td>\n",
       "      <td>src</td>\n",
       "      <td>well respect role european parliament new euro...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>overweight becoming common</td>\n",
       "      <td>src</td>\n",
       "      <td>alarming indicator showing common overweight b...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>yet</td>\n",
       "      <td>src</td>\n",
       "      <td>long way solving one</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>need flexibility emphasized resolution</td>\n",
       "      <td>src</td>\n",
       "      <td>therefore endorse emphasis resolution need use...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>similar measure italy led development austrian...</td>\n",
       "      <td>src</td>\n",
       "      <td>austrian tax exemption invested profit develop...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>cyber crime priority u work future</td>\n",
       "      <td>src</td>\n",
       "      <td>strategy cybercrime clearly identified one pri...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>encouraged several recommendation parliament</td>\n",
       "      <td>src</td>\n",
       "      <td>several recommendation parliament encouraging ...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>many difficult problem industry solved exercise</td>\n",
       "      <td>src</td>\n",
       "      <td>exercise largely irrelevant solve many difficu...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>apologize receive travel expense mr president</td>\n",
       "      <td>src</td>\n",
       "      <td>mr president wanted say sorry decided receive ...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>commission proposal looked council</td>\n",
       "      <td>src</td>\n",
       "      <td>council look aspect develops view commission p...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>reward much greater punishment continue cause ...</td>\n",
       "      <td>src</td>\n",
       "      <td>continue inflict damage environment reward far...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>method followed state</td>\n",
       "      <td>src</td>\n",
       "      <td>state liberty follow method</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>gun air</td>\n",
       "      <td>src</td>\n",
       "      <td>gun dropped beside</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>union operate broader area</td>\n",
       "      <td>src</td>\n",
       "      <td>first union operate within broader field activ...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>anything</td>\n",
       "      <td>src</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>health care improved familiar working environment</td>\n",
       "      <td>src</td>\n",
       "      <td>familiar working environment able intervene ea...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>camera discussed everything else</td>\n",
       "      <td>src</td>\n",
       "      <td>everything else discussed camera</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>globalisation fund effect different</td>\n",
       "      <td>src</td>\n",
       "      <td>effect globalisation fund already set opposite</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>grateful</td>\n",
       "      <td>src</td>\n",
       "      <td>sincerely grateful</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>new situation palestinian affected</td>\n",
       "      <td>src</td>\n",
       "      <td>affect new situation palestinian apply money m...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>necessary level safety obligation rail operator</td>\n",
       "      <td>src</td>\n",
       "      <td>rail operator state owned private obligation p...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>young farmer need hope encouragement succeed</td>\n",
       "      <td>src</td>\n",
       "      <td>must give hope young farmer encourage young pe...</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>risk use nothing</td>\n",
       "      <td>src</td>\n",
       "      <td>however nothing risk involved use</td>\n",
       "      <td></td>\n",
       "      <td>tuner007/pegasus_paraphrase</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hyp  ref  \\\n",
       "189      debate friday vote later date kept per agenda  src   \n",
       "190  iraq become prominent international agenda pas...  src   \n",
       "192                   achievement enlargement historic  src   \n",
       "193                       eurobonds example second one  src   \n",
       "194           mr doyle want ask supplementary question  src   \n",
       "195                             clear europe inclusive  src   \n",
       "196                        want tell mr colom know win  src   \n",
       "197                                         clear case  src   \n",
       "201      question surrounding eurostat raised two year  src   \n",
       "202                               fact show make worse  src   \n",
       "204                          two different signal sent  src   \n",
       "205          erdf could used improve energy efficiency  src   \n",
       "207                         world need conflict moment  src   \n",
       "209                              envelope brought back  src   \n",
       "213                    good hunting practice important  src   \n",
       "216  think organically grown food better convention...  src   \n",
       "217                food labelling used guide good diet  src   \n",
       "220               drug addicted person reminded letter  src   \n",
       "221  foreign policy union based importance relation...  src   \n",
       "224                 thing considered voting referendum  src   \n",
       "230                                      able consumed  src   \n",
       "232             believe good idea use crude tool issue  src   \n",
       "235  method used commission resulted legal problem ...  src   \n",
       "236  amendment regulation implemented immediately d...  src   \n",
       "248                issue need tackled quickly possible  src   \n",
       "249                  good job role european parliament  src   \n",
       "252                         overweight becoming common  src   \n",
       "254                                                yet  src   \n",
       "256             need flexibility emphasized resolution  src   \n",
       "257  similar measure italy led development austrian...  src   \n",
       "260                 cyber crime priority u work future  src   \n",
       "269       encouraged several recommendation parliament  src   \n",
       "273    many difficult problem industry solved exercise  src   \n",
       "278      apologize receive travel expense mr president  src   \n",
       "280                 commission proposal looked council  src   \n",
       "282  reward much greater punishment continue cause ...  src   \n",
       "287                              method followed state  src   \n",
       "288                                            gun air  src   \n",
       "290                         union operate broader area  src   \n",
       "293                                           anything  src   \n",
       "298  health care improved familiar working environment  src   \n",
       "300                   camera discussed everything else  src   \n",
       "301                globalisation fund effect different  src   \n",
       "303                                           grateful  src   \n",
       "304                 new situation palestinian affected  src   \n",
       "305    necessary level safety obligation rail operator  src   \n",
       "310       young farmer need hope encouragement succeed  src   \n",
       "311                                   risk use nothing  src   \n",
       "\n",
       "                                                   src tgt  \\\n",
       "189  propose therefore keep arrangement per agenda ...       \n",
       "190  past week iraq figured prominently minister sa...       \n",
       "192   enlargement accomplishment historic significance       \n",
       "193                   second example relates eurobonds       \n",
       "194          wish pose supplementary question mr doyle       \n",
       "195               parity clear signal inclusive europe       \n",
       "196  mr president like tell mr colom naval indeed k...       \n",
       "197                                      already clear       \n",
       "201  would draw attention fact question surrounding...       \n",
       "202                  exacerbate fact situation showing       \n",
       "204                 allows u send two different signal       \n",
       "205  possibility using erdf energy efficiency progr...       \n",
       "207         would end saying world acute need conflict       \n",
       "209                               brings back envelope       \n",
       "213                clear good hunting practice crucial       \n",
       "216  believe organic food automatically healthier b...       \n",
       "217  lastly stated food labelling never manual good...       \n",
       "220  letter reminded drug addict denial addicted su...       \n",
       "221  absolutely doubt transatlantic relation essent...       \n",
       "224  seriously consider thing deciding way vote ref...       \n",
       "230                      yet eminently fit consumption       \n",
       "232  belief incorrect use crude tool common europea...       \n",
       "235  succeeded overcoming certain legal complicatio...       \n",
       "236  make appropriate decision today office begin i...       \n",
       "248                   need tackle issue matter urgency       \n",
       "249  well respect role european parliament new euro...       \n",
       "252  alarming indicator showing common overweight b...       \n",
       "254                               long way solving one       \n",
       "256  therefore endorse emphasis resolution need use...       \n",
       "257  austrian tax exemption invested profit develop...       \n",
       "260  strategy cybercrime clearly identified one pri...       \n",
       "269  several recommendation parliament encouraging ...       \n",
       "273  exercise largely irrelevant solve many difficu...       \n",
       "278  mr president wanted say sorry decided receive ...       \n",
       "280  council look aspect develops view commission p...       \n",
       "282  continue inflict damage environment reward far...       \n",
       "287                        state liberty follow method       \n",
       "288                                 gun dropped beside       \n",
       "290  first union operate within broader field activ...       \n",
       "293                                                          \n",
       "298  familiar working environment able intervene ea...       \n",
       "300                   everything else discussed camera       \n",
       "301     effect globalisation fund already set opposite       \n",
       "303                                 sincerely grateful       \n",
       "304  affect new situation palestinian apply money m...       \n",
       "305  rail operator state owned private obligation p...       \n",
       "310  must give hope young farmer encourage young pe...       \n",
       "311                  however nothing risk involved use       \n",
       "\n",
       "                           model task  label  p(Hallucination)  \n",
       "189  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "190  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "192  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "193  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "194  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "195  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "196  tuner007/pegasus_paraphrase   PG      1               1.0  \n",
       "197  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "201  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "202  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "204  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "205  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "207  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "209  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "213  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "216  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "217  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "220  tuner007/pegasus_paraphrase   PG      1               1.0  \n",
       "221  tuner007/pegasus_paraphrase   PG      1               1.0  \n",
       "224  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "230  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "232  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "235  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "236  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "248  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "249  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "252  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "254  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "256  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "257  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "260  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "269  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "273  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "278  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "280  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "282  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "287  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "288  tuner007/pegasus_paraphrase   PG      1               1.0  \n",
       "290  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "293  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "298  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "300  tuner007/pegasus_paraphrase   PG      1               1.0  \n",
       "301  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "303  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "304  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "305  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "310  tuner007/pegasus_paraphrase   PG      0               0.0  \n",
       "311  tuner007/pegasus_paraphrase   PG      0               0.0  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_df_highscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save before_dataaug files based on task, that only has scores 0.0 or 1.0\n",
    "# dm_df_highscore.to_json(\"dm_df_highscore.json\")\n",
    "# pg_df_highscore.to_json(\"pg_df_highscore.json\")\n",
    "# mt_df_highscore.to_json(\"mt_df_highscore.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name of dataset here, continue using same name balanced_dataset\n",
    "# balanced_dataset = dm_df\n",
    "# balanced_dataset = pg_df\n",
    "balanced_dataset = mt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agg column with tgt + hyp\n",
    "balanced_dataset[\"agg\"] = \"hyp: \" + balanced_dataset[\"hyp\"] + \\\n",
    "    \" tgt: \" + balanced_dataset[\"tgt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset before data aug\n",
    "# X, y = pg_df['hyp'], pg_df['label']\n",
    "# X, y = dm_df['hyp'], dm_df['label']\n",
    "# X, y = mt_df['hyp'], mt_df['label']\n",
    "\n",
    "# task PG\n",
    "# X, y = pg_rd[['hyp','tgt']] , pg_rd['label']\n",
    "# X, y = pg_ri[['hyp','tgt']] , pg_ri['label']\n",
    "# X, y = pg_rs[['hyp','tgt']] , pg_rs['label']\n",
    "# X, y = pg_sr[['hyp','tgt']] , pg_sr['label']\n",
    "# task DM\n",
    "# X, y = dm_rd[['hyp','tgt']] , dm_rd['label']\n",
    "# X, y = dm_ri[['hyp','tgt']], dm_ri['label']\n",
    "# X, y = dm_rs[['hyp','tgt']] , dm_rs['label']\n",
    "# X, y = dm_sr[['hyp','tgt']] , dm_sr['label']\n",
    "# task MT\n",
    "# X, y = mt_rd[['hyp','tgt']] , mt_rd['label']\n",
    "# X, y = mt_ri[['hyp','tgt']] , mt_ri['label']\n",
    "# X, y = mt_rs[['hyp','tgt']] , mt_rs['label']\n",
    "# X, y = mt_sr[['hyp','tgt']] , mt_sr['label']\n",
    "\n",
    "# X, y = df['hyp'], df['label']\n",
    "# one way of getting label where task is DM, df.loc[df['task'] == 'DM', 'label']\n",
    "# X, y = df[df['task'] == 'PG']['hyp'], df[df['task'] == 'PG']['label']\n",
    "\n",
    "# task PG\n",
    "# X, y = pg_rd_160[['hyp','tgt']] , pg_rd_160['label']\n",
    "# X, y = pg_ri_160[['hyp','tgt']] , pg_ri_160['label']\n",
    "# X, y = pg_rs_160[['hyp','tgt']] , pg_rs_160['label']\n",
    "# X, y = pg_sr_160[['hyp','tgt']] , pg_sr_160['label']\n",
    "# pg_sr_160 for some reason does not have any tgt values in all rows??\n",
    "\n",
    "# task DM\n",
    "# X, y = dm_rd_160[['hyp','tgt']] , dm_rd_160['label']\n",
    "# X, y = dm_ri_160[['hyp','tgt']] , dm_ri_160['label']\n",
    "# X, y = dm_rs_160[['hyp','tgt']] , dm_rs_160['label']\n",
    "# X, y = dm_sr_160[['hyp','tgt']] , dm_sr_160['label']\n",
    "X, y = balanced_dataset['agg'] , balanced_dataset['label']\n",
    "# dm_sr_160 had basically the same amount of entrie of class 0 and 1\n",
    "# Counter({0: 4158, 1: 3738}), so i skipped making balanced dataset\n",
    "# task MT\n",
    "# X, y = mt_rd_160[['hyp','tgt']] , mt_rd_160['label']\n",
    "# X, y = mt_ri_160[['hyp','tgt']] , mt_ri_160['label']\n",
    "# X, y = mt_rs_160[['hyp','tgt']] , mt_rs_160['label']\n",
    "# X, y = mt_sr_160[['hyp','tgt']] , mt_sr_160['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 97, 1: 91})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "# y.value_counts()\n",
    "counter = collections.Counter(y)\n",
    "counter\n",
    "# just as reference, pg_rd from thesis_data_after directory has 750 entry in total\n",
    "# 480 is 0 and 270 is 1\n",
    "# but pg_rs after lemmatizing and using 160 data aug,\n",
    "# total: about 5200, 0 is 4158 and 1is 1092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example text url email example example com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Make text lowercase, remove text in square brackets, remove links, remove punctuation,\n",
    "    and remove words containing numbers.\n",
    "    '''\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(rf'[{re.escape(string.punctuation)}]', ' ', text)\n",
    "    \n",
    "    # Remove new lines\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def preprocess_data(text):\n",
    "    text = clean_text(text)  # Clean punctuation, URLs, and so on\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    # Lemmatize all the words in the sentence\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "example_text = \"This is an example text with a URL: http://example.com and an email: example@example.com.\"\n",
    "cleaned_text = preprocess_data(example_text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# paths to final test data\n",
    "final_ag_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/final_test_data/test.model-agnostic.json'\n",
    "final_aw_path = 'C:/Users/marko/OneDrive/바탕 화면/semeval/Task 6 - windows/final_test_data/test.model-agnostic.json'\n",
    "\n",
    "final_ag_df = pd.read_json(final_ag_path, encoding_errors='backslashreplace')\n",
    "final_aw_df = pd.read_json(final_aw_path, encoding_errors='backslashreplace')\n",
    "final_ag_df[\"label\"] = final_ag_df[\"label\"].map({\"Hallucination\":1, \"Not Hallucination\":0})\n",
    "final_aw_df[\"label\"] = final_aw_df[\"label\"].map({\"Hallucination\":1, \"Not Hallucination\":0})\n",
    "# perform preprocessing on final_df AND split it based on tasks!\n",
    "columns = ['hyp','src','tgt'] # exclude task\n",
    "for x in columns:\n",
    "    final_ag_df[x] = final_ag_df[x].apply(preprocess_data)\n",
    "for x in columns:\n",
    "    final_aw_df[x] = final_aw_df[x].apply(preprocess_data)\n",
    "final_ag_pg = final_ag_df[final_ag_df['task'] == 'PG']\n",
    "final_ag_dm = final_ag_df[final_ag_df['task'] == 'DM']\n",
    "final_ag_mt = final_ag_df[final_ag_df['task'] == 'MT']\n",
    "\n",
    "final_aw_pg = final_aw_df[final_aw_df['task'] == 'PG']\n",
    "final_aw_dm = final_aw_df[final_aw_df['task'] == 'DM']\n",
    "final_aw_mt = final_aw_df[final_aw_df['task'] == 'MT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFRobertaForSequenceClassification\n",
    "\n",
    "# Load tokenizer and model\n",
    "checkpoint = 'FacebookAI/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = TFRobertaForSequenceClassification.from_pretrained(checkpoint, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 188/188 [00:00<00:00, 2421.81 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset = datasets.Dataset.from_pandas(balanced_dataset)\n",
    "BATCH_SIZE=8\n",
    "# Define the tokenization function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['agg'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "# Tokenize the dataset\n",
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets_mapped = dataset.map(tokenize_function, batched=True, batch_size=BATCH_SIZE, remove_columns=['hyp','tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import tensorflow as tf\n",
    "\n",
    "# Extract embeddings function\n",
    "def extract_embeddings(inputs):\n",
    "    input_ids = tf.convert_to_tensor(inputs['input_ids'], dtype=tf.int32)\n",
    "    attention_mask = tf.convert_to_tensor(inputs['attention_mask'], dtype=tf.int32)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states[-1]\n",
    "    return hidden_states[:, 0, :].numpy()\n",
    "\n",
    "# i was thinking of splitting embeddings or dataset to train and test but...maybe laters\n",
    "embeddings = extract_embeddings(tokenized_datasets_mapped)\n",
    "# embeddings2 = extract_embeddings(tokenized_datasets_mapped)\n",
    "# embeddings3 = extract_embeddings(tokenized_datasets_mapped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=50, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=50, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameter Tuning with Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "xgb = XGBClassifier()\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(embeddings, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 562/562 [00:00<00:00, 2442.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# change this place to change final_dataset\n",
    "# copy_final_dataset = final_ag_pg\n",
    "# copy_final_dataset = final_ag_dm\n",
    "copy_final_dataset = final_ag_mt\n",
    "copy_final_dataset[\"agg\"] = \"hyp: \" + copy_final_dataset[\"hyp\"] + \\\n",
    "    \" tgt: \" + copy_final_dataset[\"tgt\"] + \\\n",
    "    \" src: \" + copy_final_dataset[\"src\"]\n",
    "X_final, y_final = copy_final_dataset['agg'], copy_final_dataset['label']\n",
    "final_dataset = datasets.Dataset.from_pandas(copy_final_dataset)\n",
    "\n",
    "\n",
    "final_tokenized = final_dataset.map(tokenize_function, batched=True, batch_size=BATCH_SIZE, remove_columns=['hyp','tgt'])\n",
    "final_embeddings = extract_embeddings(final_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 278, 1: 97})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = collections.Counter(final_ag_pg['label'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.5925266903914591\n",
      "Best Confusion Matrix:\n",
      " [[308  28]\n",
      " [201  25]]\n",
      "Best Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73       336\n",
      "           1       0.47      0.11      0.18       226\n",
      "\n",
      "    accuracy                           0.59       562\n",
      "   macro avg       0.54      0.51      0.45       562\n",
      "weighted avg       0.55      0.59      0.51       562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(final_embeddings)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_final, y_pred_best))\n",
    "print(\"Best Confusion Matrix:\\n\", confusion_matrix(y_final, y_pred_best))\n",
    "print(\"Best Classification Report:\\n\", classification_report(y_final, y_pred_best))\n",
    "# all 500,500 entries\n",
    "# dm on pg = 0.64\n",
    "# dm on dm = 0.560\n",
    "# dm on mt = 0.559\n",
    "\n",
    "# pg on pg = 0.584\n",
    "# pg on dm = 0.476\n",
    "# pg on mt = 0.407\n",
    "\n",
    "# mt on pg = 0.730\n",
    "# mt on dm = 0.524\n",
    "# mt on mt = 0.562\n",
    "\n",
    "# not using data augmentation\n",
    "\n",
    "# dm on pg = 0.656 CM = 212, 66, 63, 34\n",
    "# dm on dm = 0.556 CM = 86, 189, 61, 227\n",
    "# dm on mt = 0.470 CM = 102, 234, 64, 162\n",
    "\n",
    "# for CM, the first two numbers are prediction for 0, and the latter two for 1\n",
    "# for example final_ag_pg has 0: 278, 1:97 and pg on pg here just predicted all 370 entries as 0\n",
    "# pg on pg = 0.741 CM = 278, 0,  97, 0\n",
    "# pg on dm = 0.488 CM = 275, 0, 288, 0\n",
    "# pg on mt = 0.598 CM = 336, 0, 226, 0\n",
    "\n",
    "# mt on pg = 0.731, CM = 263, 15, 86, 11\n",
    "# mt on dm = 0.522, CM = 58, 217, 52, 236\n",
    "# mt on mt = 0.493, CM = 308, 28, 201, 25\n",
    "\n",
    "# using only data with scores 0 or 1!, from data augmentation!\n",
    "# which would warrant the need to count amount of data with only 0 and 1 before and after data aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 349, 1: 26})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "final_binary_counter = Counter(y_pred_best)\n",
    "final_binary_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7306666666666667\n",
      "Best Confusion Matrix:\n",
      " [[263  15]\n",
      " [ 86  11]]\n",
      "Best Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84       278\n",
      "           1       0.42      0.11      0.18        97\n",
      "\n",
      "    accuracy                           0.73       375\n",
      "   macro avg       0.59      0.53      0.51       375\n",
      "weighted avg       0.67      0.73      0.67       375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_xgb.predict(final_embeddings)\n",
    "print(\"Best Accuracy:\", accuracy_score(y_final, y_pred_best))\n",
    "print(\"Best Confusion Matrix:\\n\", confusion_matrix(y_final, y_pred_best))\n",
    "print(\"Best Classification Report:\\n\", classification_report(y_final, y_pred_best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
